---
title: "Thesis Simulation Document for Chapter 4"
author: "Dasha Asienga"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: TRUE

---

```{r setup, include=FALSE}
library(mosaic)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
library(knitr)
library(kableExtra)
library(ggplot2)
library(GGally)
library(MASS)
library(reshape2)
library(pROC)
```

$\\$

This file is intended to contain all the code and information to set up the simulation study and supplement Chapter 4.

# Data Generation Mechanism #1 (class balance)

We're interested in creating a data set that has 50-50 class balance, even across the demographic group, and also has better predictive performance than the COMPAS tool. For this set-up, we will only use 2 variables from the COMPAS data set: 1 continuous variable and 1 categorical variable.

## Reading in the Data

First, let's read in the data. 

```{r}
compas_path <- "/home/dasienga24/Statistics-Senior-Honors-Thesis/Data Sets/COMPAS/compas_seldonian_bw.csv"
compas_sim <- read.csv(compas_path)
```

## Data Subsetting

Next, let's plot the distributions of the continuous variables to choose which one we'll proceed with.

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim %>%
  ggplot(mapping = aes(x = age)) +
  geom_histogram() +
  theme_minimal() +
  labs(title = "Age")
```

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim %>%
  ggplot(mapping = aes(x = priors_count)) +
  geom_histogram() +
  theme_minimal() +
  labs(title = "Priors Count",
       x = "priors count")
```

$\\$

Because age has more variation, we'll use it as our continuous variable. We'll convert `priors_count` into a categorical variable.

```{r}
compas_sim <- compas_sim %>%
  mutate(prior_offense = ifelse(priors_count > 0, 1, 0)) %>%
  dplyr::select(c(race, prior_offense, age, is_recid))
```

$\\$

`age` seems to be a useful predictor for recidivism.

```{r}
favstats(age ~ is_recid, data = compas_sim)
```

$\\$

Whether a defendant has committed a prior offense or not appears to be a useful predictor for recidivism as well. 

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim %>%
  ggplot(mapping = aes(x = as.factor(prior_offense), fill = as.factor(is_recid))) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Committed a Prior Offense",
       fill = "Recidivism",
       x = "prior offense")
```

$\\$

We'll proceed with these 2 variables -- `age` and `prior_offense` for the simulation study. A glimpse of the data is shown below.

```{r}
compas_sim <- compas_sim %>%
  mutate(prior_offense = as.factor(prior_offense),
         is_recid = as.factor(is_recid))

glimpse(compas_sim)
head(compas_sim)
```

## Generating the Parent Simulation Data Set 

We want a setting with 50-50 class balance for each combination of race and recidivism status. To achieve that, we'll perform sample observations with replacement. Let's create a data set with 1250 observations in each of these 4 groups, hence, 5000 observations total.

$\\$

First, let's subset these 4 groups.

```{r}
compas_b_y <- compas_sim %>%
  filter(race == "African-American" & is_recid == 1)

compas_b_n <- compas_sim %>%
  filter(race == "African-American" & is_recid == 0)

compas_w_y <- compas_sim %>%
  filter(race == "Caucasian" & is_recid == 1)

compas_w_n <- compas_sim %>%
  filter(race == "Caucasian" & is_recid == 0)
```

$\\$

Next, let's randomly sample 1250 observations from each of these groups.

```{r}
compas_b_y_balanced <- compas_b_y[sample(nrow(compas_b_y), 1250, replace = TRUE),]
compas_b_n_balanced <- compas_b_n[sample(nrow(compas_b_n), 1250, replace = TRUE),]
compas_w_y_balanced <- compas_w_y[sample(nrow(compas_w_y), 1250, replace = TRUE),]
compas_w_n_balanced <- compas_w_n[sample(nrow(compas_w_n), 1250, replace = TRUE),]
```

$\\$

Finally, let's union all these together into a single data set.

```{r}
compas_sim_balanced <- rbind(compas_b_y_balanced, 
                             compas_b_n_balanced, 
                             compas_w_y_balanced, 
                             compas_w_n_balanced)
```

$\\$

Let's also shuffle the data set row orderings to aid the machine learning algorithms later.

```{r}
compas_sim_balanced <- compas_sim_balanced[sample(nrow(compas_sim_balanced), 
                                                  5000, 
                                                  replace = FALSE),]
```

$\\$

The parent data set is now ready. 

## Examining Distributions of the Recidivism in the Parent Data Set

The bar plot below shows that we've achieve perfect class balance.

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim_balanced %>%
  ggplot(mapping = aes(x = is_recid)) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Recidivism",
       title = "Recidivism Prevalence")
```

$\\$

The bar plot below reveals that the balance is preserved by race as well. 

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim_balanced %>%
  ggplot(mapping = aes(x = is_recid, fill = race)) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Recidivism",
       title = "Recidivism Prevalence by Race")
```

## Assessing Baseline Predictive Performance of the Parent Data Set 

We want to make sure that our data set also has good predictive performance. We'll fit a logistic regression and assess baseline accuracy. 

```{r}
glm1 <- glm(is_recid ~ age + prior_offense,
            data = compas_sim_balanced,
            family = binomial(logit))

msummary(glm1)
```


```{r}
glm1augment <- glm1 %>% 
  broom::augment(type.predict = "response")
glm1augment <- mutate(glm1augment, binprediction = round(.fitted, 0)) 
with(glm1augment, table(is_recid, binprediction))
```

```{r}
(1334 + 1713)/5000
```

This model has 61% accuracy. 

# Data Generation Mechanism #2 (better predictive performance)

Using the balanced data set created above, we'll simulate $Y$ values that have a stronger correlation with the 2 predictors. This is in an aim to hopefully ge better predictive performance, in addition to the class balance.

$\\$

## Generating the Parent Simulation Data Set 

```{r}
# define a linear combination of predictors as desired
linear_combination = - 15 - 24 * compas_sim_balanced$age + ifelse(compas_sim_balanced$prior_offense == 1, 1000, -10)

# pass through an inverse-logit function
probs = exp(linear_combination) / (1 + exp(linear_combination))  

# generate 5000 Bernoulli RVs for y
is_recid_sim = rbinom(5000, 1, probs) 

# join to original data frame
compas_sim_balanced_2 <- cbind(compas_sim_balanced, is_recid_sim)
```

$\\$

There are 2487 defendants who did not recidivate in this data set. 

```{r}
count(compas_sim_balanced_2$is_recid_sim == 0)
```

$\\$

There are 2513 defendants who recidivated in this data set. 

```{r}
count(compas_sim_balanced_2$is_recid_sim == 1)
```

$\\$

The data set seems pretty balanced. Let's look at this distribution in more detail, though. 

## Examining Distributions of the Recidivism in the Parent Data Set

The bar plot below confirms the balanced nature of this new data set. 

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim_balanced_2 %>%
  ggplot(mapping = aes(x = as.factor(is_recid_sim))) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Recidivism",
       title = "Simulated Recidivism Prevalence")
```

$\\$

However, the balance is not perfectly achieved by race. Some of the proxy relationships present in the predictor variables have influenced the distribution of the $Y$ variable by race. 

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim_balanced_2 %>%
  ggplot(mapping = aes(x = race, fill = as.factor(is_recid_sim))) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Race",
       title = "Simulated Recidivism Prevalence by Race",
       fill = "Recidivism")
```

## Assessing Baseline Predictive Performance of the Parent Data Set 

We want to make sure that our data set also has good predictive performance. We'll fit a logistic regression and assess baseline accuracy. 

```{r, warning = FALSE, message = FALSE}
glm2 <- glm(is_recid_sim ~ age + prior_offense,
            data = compas_sim_balanced_2,
            family = binomial(logit))

msummary(glm2)
```

```{r}
glm2augment <- glm2 %>% 
  broom::augment(type.predict = "response")
glm2augment <- mutate(glm2augment, binprediction = round(.fitted, 0)) 
with(glm2augment, table(is_recid_sim, binprediction))
```

```{r}
(2475 + 2513)/ 5000
```

This data set has 99.76% accuracy, although the distribution of race is affected. There is barely any error, so this may not be too useful for our fairness definition. 

# Data Generation Mechanism #3 (class balance and better predictive performance)

Let's introduce some balance across racial lines.

$\\$

First, let's subset these 4 groups.

```{r}
compas_b_y <- compas_sim_balanced_2 %>%
  filter(race == "African-American" & is_recid_sim == 1)

compas_b_n <- compas_sim_balanced_2 %>%
  filter(race == "African-American" & is_recid_sim == 0)

compas_w_y <- compas_sim_balanced_2 %>%
  filter(race == "Caucasian" & is_recid_sim == 1)

compas_w_n <- compas_sim_balanced_2 %>%
  filter(race == "Caucasian" & is_recid_sim == 0)
```

$\\$

Next, let's randomly sample 1250 observations with replacement from each of the 4 groups in the new data set.

```{r}
compas_b_y_balanced <- compas_b_y[sample(nrow(compas_b_y), 1250, replace = TRUE),]
compas_b_n_balanced <- compas_b_n[sample(nrow(compas_b_n), 1250, replace = TRUE),]
compas_w_y_balanced <- compas_w_y[sample(nrow(compas_w_y), 1250, replace = TRUE),]
compas_w_n_balanced <- compas_w_n[sample(nrow(compas_w_n), 1250, replace = TRUE),]
```

$\\$

Finally, let's union all these together into a single data set.

```{r}
compas_sim_balanced_3 <- rbind(compas_b_y_balanced, 
                               compas_b_n_balanced, 
                               compas_w_y_balanced, 
                               compas_w_n_balanced)
```

$\\$

Let's also shuffle the data set row orderings to aid the machine learning algorithms later.

```{r}
compas_sim_balanced_3 <- compas_sim_balanced_3[sample(nrow(compas_sim_balanced_3), 
                                                      5000, 
                                                      replace = FALSE),]
```


$\\$

The data set is now ready. 

## Examining Distributions of the Recidivism in the Parent Data Set

The bar plot below confirms the balanced nature of this new data set. 

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim_balanced_3 %>%
  ggplot(mapping = aes(x = as.factor(is_recid_sim))) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Recidivism",
       title = "Simulated Recidivism Prevalence")
```

$\\$

The balance is also preserved by race. 

```{r, warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, fig.align = 'center'}
compas_sim_balanced_3 %>%
  ggplot(mapping = aes(x = race, fill = as.factor(is_recid_sim))) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Race",
       title = "Simulated Recidivism Prevalence by Race",
       fill = "Recidivism")
```

## Assessing Baseline Predictive Performance of the Parent Data Set 

We want to make sure that our data set also has good, but not perfect, predictive performance. We'll fit a logistic regression and assess baseline accuracy. 

```{r, warning = FALSE, message = FALSE}
glm3 <- glm(is_recid_sim ~ age + prior_offense,
            data = compas_sim_balanced_3,
            family = binomial(logit))

msummary(glm3)
```

```{r}
glm3augment <- glm3 %>% 
  broom::augment(type.predict = "response")
glm3augment <- mutate(glm3augment, binprediction = round(.fitted, 0)) 
with(glm3augment, table(is_recid_sim, binprediction))
```

$\\$

The accuracy is a little bit too good. For the final mechanism, we will follow this framework, but weaken the strengths of the correlations. 

# Data Generation Mechanism #4 (class balance, but with some error)

This research paper explores the challenge of algorithmic bias in machine learning (ML) and artificial intelligence (AI) systems and investigates the feasibility of producing fairer models. Chapter 1 examines various mathematical definitions of fairness, highlighting conflicts in their simultaneous enforcement and emphasizing the importance of human judgment in selecting relevant metrics. Chapter 2 introduces the Seldonian framework as a means to address unfair outcomes from traditional ML algorithms by setting probabilistic fairness constraints. Chapter 3 applies the Seldonian framework to the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) data set, demonstrating its ability to meet fairness constraints despite tradeoffs with model performance. Chapter 4 further evaluates Seldonian algorithms in practical classification settings through a simulation study, highlighting pressing concerns about obtaining solutions that meet fairness constraints and retain predictive performance. The results of this research study necessitate ongoing research to optimize fairness and predictive performance while acknowledging the complexity of fairness in ML and AI systems. Future work involves exploring subgroup and individual fairness, comparing Seldonian outcomes with other fair ML tools, and integrating social and technical considerations. Overall, the study underscores the progress, challenges, and necessity of mitigating harm in ML and AI systems through collaborative social and technical efforts.

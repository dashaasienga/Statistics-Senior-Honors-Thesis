
```{r load_packages, include = FALSE}
library(mosaic)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
```

# Seldonian Algorithms {#chap-2}

Chapter \@ref(intro) introduced the problem of algorithmic bias, discussed existing statistical definitions of fairness both in regression and classification settings, and finally, highlighted  fairness conflicts that can arise in certain settings. Of important note is that there are a plethora of fairness definitions that have been developed in statistical machine learning, many of which have been shown to be incompatible in ways similar to the illustration in Appendix \@ref(appendix-a). In any effort to enforce fairness on machine learning models, a critical first step is to define what fairness means in the specific context [@thomas2020housetestimony]. This responsibility falls on domain experts, social scientists, and regulators. Once there is consensus on that, machine learning researchers can work to develop appropriate algorithms that enforce the chosen definition of fairness. The Seldonian framework, introduced in this chapter, offers one such way to place probabilistic fairness constraints on traditional algorithms. However, because Seldonian algorithms place constraints on traditional machine learning (ML) algorithms, an initial in-depth understanding of the standard approach is key. Section \@ref(standardml) discusses the typical ML approach before diving into the Seldonian framework in Section \@ref(seldonian). 

## The Standard Machine Learning Approach {#standardml}

When designing a machine learning algorithm, the first step is to mathematically define what the algorithm should do, in other words, the goal of the algorithm [@thomas2019supplementary]. At an abstract level, this goal is identical for all machine learning problems: find a solution $\theta^*$, within some feasible set $\Theta$, that maximizes some objective function $f: \Theta \rightarrow \textbf{R}$, where $\textbf{R}$ is the set of real numbers. Precisely, the goal of the algorithm is to search for an optimal solution  

\begin{equation}
\label{ch2eq1}
\theta^* \in \underset{\theta \in \Theta}{\text{ arg max }} f(\theta).
\end{equation}

For example, let $X$ and $Y$ be dependent real-valued random variables in a regression setting with the goal of estimating $Y$ given $X$. In this setting, $\Theta$ is the set of feasible functions that model the relationship between $X$ and $Y$. Feasible functions are of the form $\theta(X) = \beta_0 + \beta_1X = \hat{Y}$. Each function $\theta \in \Theta$ takes a real number as input and produces a real number as output; therefore, $\theta : \textbf{R} \rightarrow \textbf{R}$. A reasonable objective function would then be the negative mean squared error (MSE):

\begin{equation}
\label{ch2eq2}
f(\theta):=-E[(\theta(X) - Y)^2].
\end{equation}

In this case, minimizing MSE is equivalent to maximizing -MSE, defining the goal of the regression algorithm as finding the solution with the least average error. Note that the true value of $f(\theta)$ is unknown and can only be estimated from the data [@thomas2019preventing]. For a sample with $n$ observations, that is, $(x_i, y_i) \text{ for } i = 1,2,...,n$, the objective function can be estimated by:

\begin{equation}
\label{ch2eq3}
\hat{f(\theta)}= -\frac{1}{n} \sum_{i=1}^{n}(\theta(x_i) - y_i)^2.
\end{equation}

However, defining objective functions in this way can sometimes lead to undesirable behavior as illustrated in Section \@ref(standardlimitations).

### Limitations of the Standard Approach {#standardlimitations}

Consider a linear regression example to predict the qualifications of job applicants based on information on their resumes. Let $G$ encode the gender of each applicant, with $G=0$ if the applicant is female and $G=1$ if the applicant is male. Let $X$ encode a summary measure of an applicant's qualification based on information on their resume -- a simple example would be a measure of how many job-relevant key words appear on their resume. Let $Y$ encode their actual qualification for the job as determined by their observed performance. 

If this linear regression estimator is designed to be used to filter which resumes submitted to a company will be forwarded for human review, it is worthwhile to ensure that the algorithm does not produce racist or sexist behavior. Drawing from definitions in Chapter \@ref(fairnessdefinitions), it might be less important to ensure that the algorithm, on average, has the same predictions for applicants of both genders because the distribution of qualifications may be different for both genders. However, of more concern is whether the algorithm, on average, predicts too high for one gender and too low for the other gender. 

Suppose that the data has the following distribution: $Y \sim N(1,1)$ if $G = 0$ and $Y \sim N(-1,1)$ if $G = 1$, that is, $Y$ is a normal variable $N(\mu, \sigma)$ with different means $\mu$ for different genders but with the same standard deviation $\sigma$ for both genders. Further define $X \sim N(Y,1)$, that is, an applicant's resume quality is equal to their true qualification plus some random noise. Figure \@ref(fig:fig1) displays a scatterplot of 1000 such data points, 500 from each gender. The black solid line is the least squares fit on this data using a gender-blind model. 


```{r fig1, fig.align='center', fig.cap="Least Squares Fit on Synthetic Data Drawn from Different Distributions", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, echo = FALSE}
# set seed for reproducibility 
set.seed(123)

# generate synthetic data for both male and female applicants
female <- rnorm(500, mean = 1, sd = 1)
male <- rnorm(500, mean = -1, sd = 1)
gender <- c(rep(0,500), rep(1,500))

# create the data set
y <- union(female, male)
x <- rnorm(1000, mean = y, sd = 1)
data <- cbind(y, x, gender)
data <- data %>%
  as.data.frame()

# create custom color scale 
myColors <- brewer.pal(2,"Set1")
names(myColors) <- levels(data$gender)

# fit least squares line
ggplot(data = data, mapping = aes(x = x, y = y)) +
  geom_point(aes(color = as.factor(gender)), alpha = 0.8) +
  geom_smooth(
    method = "lm",
    aes(color = as.factor(gender)),
    se = F,
    size = 2
  ) +
  geom_smooth(
    method = "lm",
    formula = y ~ x,
    color = 'black',
    se = F
  ) +
  scale_colour_manual(name = "Gender (G)",values = myColors) +
  labs(color = "Gender (G)",
       title = "Least Squares Fit on Synthetic Data") +
  theme_minimal() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) 
```

```{r, echo = FALSE}
# set seed for reproducibility
set.seed(123)

# obtain the least squares linear model
model <- lm(y ~ x, data = data)

# obtain the model predictions 
preds <- predict(model, newdata = data)

# add the error into the data set
data <- data %>%
  mutate(error = preds - data$y)

# compute average error per gender 
diff <- data %>%
  group_by(gender) %>%
  summarise(average = mean(error)) 

# obtain the discrimination statistic
d <- diff$average[1] - diff$average[2]
```

The least squares fit on Figure \@ref(fig:fig1) is impartial to an observation's gender with an objective to make the most accurate predictions. While it may be expected that impartiality would produce fair results, observe that the linear model tends to over-predict if $G = 1$ and under-predict if $G=0$, producing discriminatory behavior. In fact, by defining a discrimination statistic, $d(\theta)$, that measures whether the model satisfies separation (equal error rates), the discrimination statistic for the synthetic data set in Figure \@ref(fig:fig1) can be shown to be `r d`, suggesting that the model predictions are in favor of $G = 1$:
 
\begin{equation}
\label{ch2eq4}
d(\theta) =  E[\hat{Y}-Y|G = 0 ] - E[\hat{Y}-Y|G = 1 ]. 
\end{equation}


In crucial applications such as hiring, this is concerning and highlights how group-blind linear regression algorithms designed using the standard approach and following statistical best practices can result in predictions that systematically discriminate against a demographic group.


### Potential Remedies

In an attempt to remedy this undesirable behavior, a number of approaches can be taken. One potential remedy is to identify the root cause of the undesirable behavior such as class imbalance in the training data, bias in the data set, the choice of linear estimator, the model's blindness to the demographic group, or insufficient data, to name a few [@thomas2019supplementary]. For instance, in the example set up in Section \@ref(standardlimitations) and displayed in Figure \@ref(fig:fig1), the root cause of the discriminatory behavior when using ordinary least squares linear regression was the fact that the objective function was designed to minimize MSE, which was at odds with minimizing the discrimination statistic. However, even though it might be possible to determine and correct the root cause of the undesirable behavior, doing so can be difficult, error-prone, and require extensive data analysis, rendering the central goal of machine learning algorithms, which are designed to automate and make decision-making processes simpler, obsolete.

Assuming that the problem is with the objective function and provided that detailed knowledge of the problem is available, hard constraints may be placed on the objective function, for example, requiring that MSE is minimized only on the set of solutions with a discrimination value $d(\theta)$ less than some value $\epsilon$ [@thomas2019supplementary]. Additionally, rather than placing hard constraints on the set of solutions, soft constraints that penalize undesirable behavior may also be placed on $f$, the objective function [@boyd2004convex]. Although such penalty functions can be effective, they require a careful choice of the value of the parameter $\lambda$ that places relative importance on the objective function and the constraint. For the linear regression example, the new objective function with a soft constraint would now be:

\begin{equation}
\label{ch2eq5}
f(\theta) = - MSE (\theta) - \lambda d(\theta).
\end{equation}

Observe that as $\lambda$ increases, MSE increases and the discrimination statistic decreases. Cross-validation techniques can be employed to find optimal values for $\lambda$. Other remedies include maximizing multiple objective functions or allowing constraints on the probability that a solution with undesirable behavior will be returned, both of which may require detailed knowledge of the application problem and underlying distribution of the data [@thomas2019supplementary]. 

In principle, there might be definitions of $\Theta$ or $f$ that prevent the algorithm from converging on solutions that exhibit undesirable behavior [@thomas2019preventing]. However, in practice and as explained, this might require extensive domain expertise and data analysis in order to properly balance the relative importance of the objective function and the constraints, which can be at odds with each other. These techniques may also require knowledge of the probability distribution from which the data is sampled, which is not always available and limits applications to parametric statistics.

Seldonian algorithms address this problem precisely by allowing probabilistic constraints on undesirable behavior to be placed more easily without detailed knowledge of the specific problem or the distribution of the data, shifting the burden from the domain experts who use these tools to the experts in ML and statistics [@thomas2019preventing]. It's named after Isaac Asimov’s fictional character, Hari Seldon ^[In the fictional book, Hari Seldon was a resident of a fictional planet where he develops psycho-history, an algorithmic science that allows him to predict the future in probabilistic terms.] [@asimov1994forward]. It's important to note that while Seldonian algorithms allow for more seamless implementation in practice, domain experts are still needed to define the relevant fairness constraints for a given context.

## The Seldonian Framework {#seldonian}

The first step of the Seldonian framework is to define mathematically the goal of the algorithm design [@thomas2019supplementary]. Define $\textbf{D}$ as the set of all possible inputs (data sets) to the algorithm. $\Theta$, as previously defined, is the set of all possible outputs (solutions) of the algorithm. Each solution is referred to as $\theta \in \Theta$. $D$ is the data set (input) given to the algorithm and is the only random variable. Now, $a: \textbf{D} \rightarrow \Theta$ is a machine learning algorithm which takes in a data set $D \in \textbf{D}$ as an input and returns a solution $\theta \in \Theta$ as an output. $\textbf{A}$ is the set of all possible machine learning algorithms. Synthesizing this, $f: \textbf{A} \rightarrow \textbf{R}$ is the objective function of the algorithm design, where $f(a) \in \textbf{R}$ is a real-valued measure of the utility of the algorithm, such as the value of the objective function for the solution returned by this algorithm. This objective function is optimized -- either minimized or maximized -- to select a desired machine learning algorithm from the set $\textbf{A}$.

Contrary to the standard ML approach, however, $n$ behavioral constraints can then be specified [@thomas2019supplementary]. Specifically, $(g_i, \delta_i)_{i=1}^{n}$ can be defined as a set of $n$ constraints, each of which contains a constraint function $g_i: \Theta \rightarrow \textbf{R}$ and a desired confidence level $\delta_i$. The constraint function takes in a solution returned from the chosen machine learning algorithm as an input and returns a real value encoding the "fairness" of the algorithm according to the fairness definition defined by the function. $(g_i, \delta_i)_{i=1}^{n}$ is defined such that:

- The $i^{th}$ constraint function measures an undesirable behavior. Specifically, $\theta \in \Theta$ produces undesirable behavior if and only if $g_i(\theta) > 0$. This is to ensure that undesirable behavior is defined in a mathematically tractable way such as how the discrimination statistic $d(\theta)$ was defined in Section \@ref(standardlimitations).

- The $i^{th}$ confidence level specifies the maximum probability that an algorithm can return a solution $\theta$ where $g_i(\theta) > 0$. In other words, $1 - \delta_i$ specifies the minimum probability that desirable behavior ($g_i(\theta) \leq 0$) is met. Smaller values of $\delta_i$ are preferred. 

In summary, a Seldonian algorithm ensures that for all $i \in \{1,2,\ldots,n\}$:

\begin{equation}
\label{ch2eq6}
P(g_i(a(D)) \leq 0) \geq 1 - \delta_i.
\end{equation}

Section \@ref(sop) goes into further detail about the Seldonian framework and how these probabilistic behavioral constraints are guaranteed.

### The Seldonian Optimization Problem {#sop}

As detailed, the Seldonian framework is different from current potential remedies of undesirable behavior because it defines a search over a possible set of algorithms with constraints, rather than over a possible set of solutions. This means that the constraints require that the probability that a machine learning algorithm returns an unsafe solution be bounded by some desired level of confidence, rather than the probability that a solution itself is unsafe. In summary, the Seldonian optimization problem (SOP) can be written as [@thomas2019preventing]:


\begin{equation}
\label{ch2eq7}
\underset{a \in \textbf{A}}{\text{ arg max }} f(a)
\end{equation}

$$\text{ s.t. } \forall \text{ } i \in \{1, 2, \ldots, n\} \text{, } P(g_i(a(D)) \leq 0) \geq 1 - \delta_i.$$

A Seldonian algorithm $a$, thus, returns, with high probability, a solution that guarantees desirable behavior. If one were to apply machine algorithm $a$ to obtain a solution from a large number of different data sets $D$ drawn from the same distribution, then it would be expected that at most $100\delta_i \%$ solutions (models) would produce undesirable behavior. 

Taking the previous regression example and turning it into a Seldonian optimization problem using the discrimination statistic in Section \@ref(standardlimitations), $f$ would still be an objective function like the MSE, $\Theta$ would still be the set of all possible linear models, and $D$ would be the data set as described. There would be 1 behavioral constraint, $g_1(a(D)) = |d(a(D))| - \epsilon$, to guarantee with probability at least $1-\delta_1$, that the absolute value of the discrimination statistic would be at most $\epsilon$, where $\epsilon$ and $\delta_1$ are chosen by domain experts based on the specific application. Note that the user of the machine learning algorithm need not perform data analysis to determine whether $g_1(\theta) \leq 0$ for a particular solution $\theta \in \Theta$ returned. The computation algorithm guarantees this with some desired level of probability. 

```{r seldonian1, fig.cap="Overview of the Seldonian Framework (P. S. Thomas et al., 2019a)", out.width = '100%', echo=FALSE, fig.scap="Overview of the Seldonian Framework"}
include_graphics(path = "figures/seldonian1.png")
```

Figure \@ref(fig:seldonian1) illustrates how this is achieved at a high level. A Seldonian algorithm takes in $n$ behavioral constraints $(g_i,\delta_i)_{i=1}^n$ and a data set $D$ as the inputs and returns either a solution (model) $\theta$ or $NSF$, which means "No Solution Found". An NSF result means no algorithm was found that returned a model which satisfied the behavioral constraints with the desired probability, so solutions are not guaranteed when employing Seldonian algorithms. 

First, the data $D$ is partitioned into 2 sets $D_1$ and $D_2$ that essentially serve as train and test sets, respectively. $D_1$ is then passed through the candidate selection mechanism, which performs a search over algorithms to settle on a candidate solution $\theta_c$. $\theta_c$ is selected not only so that it optimizes the primary objective function $f$, but also so that it is predicted to pass the subsequent safety test. $D_2$ is then passed through the safety test to check whether $\theta_c$ indeed satisfies the $n$ behavioral constraints with the desired confidence for each, that is $P(g_i(\theta_c) \leq 0) \geq 1 - \delta_i$ for each constraint $i \in \{ 1,2, \ldots, n \}$. If so, $\theta_c$ is returned as the desired solution, and otherwise, NSF [@thomas2019preventing]. 

Note that finding exact confidence bounds may be impractical and require large amounts of data. Quasi-Seldonian algorithms, thus, are an extension of this idea that rely on standard statistical tools to transform sample statistics computed from $D$ into approximate bounds on the probability of undesirable behavior [@thomas2019preventing]. Section \@ref(qsa) discusses the statistical framework employed to achieve this. 

### Quasi-Seldonian Algorithms {#qsa}

Recall that the Seldonian goal is to create an algorithm $a$ that is an approximate solution to the Seldonian optimization problem defined in Equation \@ref(ch2eq7). This framework is non-parametric and relies on exact values of the objective function and fairness constraints. However, these values are often unknown and need to be estimated from the data provided. 

For example, $f(a)$, the objective function, can be estimated from the data provided such that $\hat{f}: \Theta \text{ x } \textbf{D} \rightarrow \textbf{R}$ serves as a measure of the utility of the algorithm that returns a solution $\theta$ when given input $D$ [@thomas2019preventing]. In a linear regression setting, the MSE for a data set of size $m$ can be estimated by

\begin{equation}
\label{ch2eq9}
\hat{f}(\theta, D) = -\frac{1}{m} \sum_{i=1}^{m}(\hat{y}(X_i, \theta) - Y_i)^2.
\end{equation}

In a similar fashion, the following section discusses how the candidate selection and safety test mechanisms further employ statistical estimation techniques to estimate the confidence bounds of the fairness constraints and probabilistically guarantee safe behavior.

#### The Safety Test Mechanism {#safety}

Seldonian algorithms ensure that $P(g_i(\theta_c) \leq 0) \geq 1 - \delta_i$ for each constraint $i \in \{ 1,2, \ldots, n \}$ and the safety test mechanism is the component that verifies whether these behavioral constraints actually hold [@thomas2019preventing]. This is achieved by computing an upper bound for each $g_i(\theta)$ using the data and a confidence interval derived from the Student $t$-statistic. If the high confidence upper bound is less than or equal to 0, then the solution is safe to return, otherwise, no solution will be returned. 

Let $X = (X_1, \ldots, X_m)$ be $m$ independent and identically distributed ($i.i.d.$) random variables. Under the assumption that $\frac{1}{m} \sum_{i=1}^m X_i$ is normally distributed or if $m$ is sufficiently large -- by the Central Limit Theorem --, then the Student $t$-statistic can be used to compute an upper bound of the expected value of these random variables as follows:

\begin{equation}
\label{ch2eq10}
P(E[X_1] \leq \hat{\mu}(X) + \frac{\hat{\sigma}(X)}{\sqrt{m}}t_{1-\delta, m-1}) \geq 1 - \delta,
\end{equation}

where

- $\hat{\mu}(X) = \bar{X}$ and $\hat{\sigma}(X) = s$ are the sample mean and standard deviation, respectively, of a vector X. That is, $\hat{\mu}(X) = \frac{1}{m}\sum_{i=1}^m X_i = \bar{X}$ and $\hat{\sigma}(X) = \sqrt{\frac{\frac{1}{m}\sum_{i=1}^m (X_i - \hat{\mu}(X))^2}{m-1}} = s$. 

- $t_{1-\delta, m-1}$ is the $100(1-\delta)$ percentile of the Student $t$-distribution with $m-1$ degrees of freedom.

Before constructing the safety test mechanism, recall from Section \@ref(sop) that [@thomas2019supplementary]:

- The safety test will be applied to a single solution $\theta_c$ selected by the candidate selection mechanism. This process is explained in the following section.  

- The safety data, $D_2$, is used to verify that the behavioral constraints hold. 

- $\hat{g_i}(\theta_c, D_2) = (\hat{g_{i,1}}(\theta_c, D_2), \ldots,\hat{g_{i,m}}(\theta_c, D_2))$ contains $m$ $i.i.d$ values of $\hat{g_i}(\theta_c)$ for each of the $m$ observations in $D_2$. $|D_2|$ will be used to denote the number of observations in $D_2$ for consistency in notation. 

- $E[\hat{g_i}(\theta_c, D_2)] = g_i(\theta_c)$.

By substituting the respective pieces into the Student $t$ high confidence upper bound discussed above, then:

\begin{equation}
\label{ch2eq11}
P(g_i(\theta_c) \leq \hat{\mu}(\hat{g_i}(\theta_c, D_2)) + \frac{\hat{\sigma}(\hat{g_i}(\theta_c, D_2))}{\sqrt{|D_2|}}t_{1-\delta_i, |D_2|-1}) \geq 1 - \delta_i.
\end{equation}


Notice that $\hat{\mu}(\hat{g_i}(\theta_c, D_2)) + \frac{\hat{\sigma}(\hat{g_i}(\theta_c, D_2))}{\sqrt{|D_2|}}t_{1-\delta_i, |D_2|-1}$ is an upper bound of the confidence interval with confidence $1-\delta_i$. If this upper bound is less than or equal to zero, then the $i^{th}$ behavioral constraint $g_i(\theta_c)$ is less than or equal to zero with at least probability $1-\delta_i$. Therefore, $\theta_c$ is only returned if $\hat{\mu}(\hat{g_i}(\theta_c, D_2)) + \frac{\hat{\sigma}(\hat{g_i}(\theta_c, D_2))}{\sqrt{|D_2|}}t_{1-\delta_i, |D_2|-1} \leq 0$. Specifically, this holds only under the assumption that $\hat{\mu}(\hat{g_i}(\theta_c, D_2))$ is normally distributed or if the size of the safety data $D_2$ is sufficiently large, hence the name $\textit{quasi}$-Seldonian [@thomas2019preventing]. The next section now discusses precisely how $\theta_c$ is selected before being passed into the safety test mechanism. 

#### The Candidate Selection Mechanism {#candidate}

With the safety test in place, any algorithm will be Seldonian regardless of how $\theta_c$ is computed, as long as $\theta_c$ is computed using a different subset of the data, hence the partition into $D_1$ (candidate data) and $D_2$ (safety data) [@thomas2019supplementary]. However, if $\theta_c$ is computed using the standard ML approach, then it will likely be unsafe as was illustrated in Section \@ref(standardlimitations), resulting in an NSF output. Instead, $\theta_c$ will be computed as follows:

\begin{equation}
\label{ch2eq12}
\theta_c \in \underset{\theta \in \Theta}{\text{ arg max }} \hat{f}(\theta, D_1)
\end{equation}

$$\text{ s.t. } \theta_c \text{ is predicted to pass the safety test}.$$


Thus, only solutions likely to pass the safety test will be considered by predicting the result of the safety test using $D_1$ (the candidate data) instead of $D_2$. In formal notation,

\begin{equation}
\label{ch2eq13}
\theta_c \in \underset{\theta \in \Theta}{\text{ arg max }} \hat{f}(\theta, D_1)
\end{equation}

$$ \text{ s.t. } \forall \text{ } i \in \{1,2,\ldots,n\}, \text{  } \hat{\mu}(\hat{g_i}(\theta_c, D_1)) + \frac{\hat{\sigma}(\hat{g_i}(\theta_c, D_1))}{\sqrt{|D_2|}}t_{1-\delta_i, |D_2|-1} \leq 0. $$


Notice that while the sample mean $\hat{\mu}$ and the sample standard deviation $\hat{\sigma}$ are computed over $D_1$, the size of $D_2$ is still used to correct the standard deviation and compute the Student $t$ percentile, in order to ensure that the solution is properly predicted to pass the safety test. 

The process defined can work well when the objective function $f$ and the behavioral constraints are aligned. However, when they are in conflict, the candidate selection mechanism tends to be over-confident that $\theta_c$ will pass the safety test and a safe solution will be returned [@thomas2019supplementary]. Doubling the width of the confidence level is a proposed solution to produce more conservative predictions and better guarantees of $\theta_c$ passing the safety test. Therefore, a black-box optimization algorithm is used to compute

\begin{equation}
\label{ch2eq14}
\theta_c \in \underset{\theta \in \Theta}{\text{ arg max }} \hat{f}(\theta, D_1)
\end{equation}

$$\text{ s.t. } \forall \text{ } i \in \{1,2,\ldots,n\}, \text{  } \hat{\mu}(\hat{g_i}(\theta_c, D_1)) + 2\frac{\hat{\sigma}(\hat{g_i}(\theta_c, D_1))}{\sqrt{|D_2|}}t_{1-\delta_i, |D_2|-1} \leq 0.$$


\

This concludes the discussion on the Seldonian theoretical framework at a high level. To conclude this Chapter, Section \@ref(toy) walks through how this is implemented computationally using a toy regression example. 

## Toy Example: A Seldonian Regression Algorithm {#toy}

The tutorial in this section follows the presentation by @aisafety on the AI Safety webpage focusing on the key computational aspects of the Seldonian Algorithm. Consistent with the linear regression set-up in this chapter, consider $X, Y \in \textbf{R}$ as two dependent random variables with the goal of estimating $Y$ given $X$ through a sample of $m$ observations. $X$ is drawn synthetically from a $N(0,1)$ distribution and $Y$ is dependent on $X$ with a $N(X,1)$ distribution. Figure \@ref(fig:fig2) displays 5000 such points. $\hat{y}(X, \theta) = \theta_1X+\theta_2$ and $MSE = E[(\hat{y}(X, \theta)-Y)^2]$ are computed as previously defined.

```{r fig2, fig.align='center', fig.cap="Synthetic Data for Seldonian Linear Regression Tutorial", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, echo = FALSE}
# set seed for reproducibility 
set.seed(123)

# generate synthetic data 
x <- rnorm(5000, mean = 0, sd = 1)
y <- rnorm(5000, mean = x, sd = 1)

# create the data set
seldonian_data <- cbind(y, x)
seldonian_data <- seldonian_data %>%
  as.data.frame()

# plot the data points
ggplot(data = seldonian_data, mapping = aes(x = x, y = y)) +
  geom_point(color = "lightblue") +
  labs(title = "Synthetic Data for Seldonian Linear Regression",
       x = "X",
       y = "Y") +
  theme_minimal() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) 
```

In this example, the goal of the linear regression algorithm is two-fold: to minimize MSE (or equivalently, maximize -MSE) while ensuring, with probability at least 0.9, that $1.25 < MSE < 2$. Note that this behavioral constraint is not practical in an application setting, but it's deliberately designed to be at odds with the objective function in order to test behavior when such conflict arises. Additionally, it'll be simple to verify satisfaction of the behavioral constraint for demonstration purposes. The behavioral constraint needs to be mathematically represented in a way that defines $g(\theta) \leq 0$ as safe behavior. Therefore, $n$ will be set to $2$ such that:

- $g_1(\theta) = MSE(\theta) - 2.0 \text{; } \delta_1 = 0.1$.

- $g_2(\theta) = 1.25 - MSE(\theta) \text{; } \delta_2 = 0.1$.

Unbiased estimates of the MSE and each $g_i(\theta)$ will be computed from the data set as elucidated in Section \@ref(qsa). The Python code used to implement and compute the Quasi-Seldonian linear regression algorithm is displayed in detail in Appendix \@ref(appendix-b). In this case, a solution that minimizes the MSE while satisfying the 2 behavioral constraints, $g_1(\theta)$ and $g_2(\theta)$, was found -- the MSE was $1.385$. Figure \@ref(fig:fig3) visually compares the quasi-Seldonian solution (blue) with the ordinary least squares solution (red). 


```{r, echo = FALSE}
library(reticulate)
use_python("/cm/shared/apps/amh-Rstudio/python-3.11.4/bin/python3", required = TRUE)
#py_config()
#conda_list()
```

```{r, echo = FALSE}
sklearn <- import("sklearn")
#conda_list()
```

```{r, include = FALSE}
py_config()
```

```{python, echo = FALSE}
import sklearn
```

```{python, echo = FALSE}
import math
import numpy as np
import sys
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from scipy.stats import t
from scipy.optimize import minimize
```

```{python, echo = FALSE}
np.set_printoptions(precision=5, suppress=True)
```

```{python, echo = FALSE}
def tinv(p, nu):
    return t.ppf(p, nu)
```

```{python, include = FALSE}
tinv(0.95,50)
```

```{python, echo = FALSE}
def stddev(v):
    n = v.size
    variance = (np.var(v) * n) / (n-1) 
    return np.sqrt(variance) 
```

```{python, echo = FALSE}
def ttestUpperBound(v, delta):
    n  = v.size
    res = v.mean() + stddev(v) / math.sqrt(n) * tinv(1.0 - delta, n - 1)
    return res
```

```{python, echo = FALSE}
def predictTTestUpperBound(v, delta, k):
    
    res = v.mean() + 2.0 * stddev(v) / math.sqrt(k) * tinv(1.0 - delta, k - 1)
    return res
```

```{python, echo = FALSE}
def main():
    np.random.seed(123)  
    numPoints = 5000   

    (X,Y)  = generateData(numPoints)  

    gHats  = [gHat1, gHat2] 
    deltas = [0.1, 0.1]

    (result, found) = QSA(X, Y, gHats, deltas) 
    
    if found:
        print("A solution was found: [%.10f, %.10f]" % (result[0], result[1]))
        print("fHat of solution (computed over all data, D):", fHat(result, X, Y))
    else:
        print("No solution found")
```

```{python, echo = FALSE}
def generateData(numPoints):
    X =     np.random.normal(0.0, 1.0, numPoints) 
    Y = X + np.random.normal(0.0, 1.0, numPoints) 
    return (X,Y)
```

```{python, echo = FALSE}
def predict(theta, x):
    return theta[0] + theta[1] * x
```

```{python, echo = FALSE}
def fHat(theta, X, Y):
    n = X.size          
    res = 0.0           
    for i in range(n):  
        prediction = predict(theta, X[i])                
        res += (prediction - Y[i]) * (prediction - Y[i]) 
    res /= n            
    return -res         
```

```{python, echo = FALSE}
def gHat1(theta, X, Y):
    n = X.size          
    res = np.zeros(n)   
    for i in range(n):
        prediction = predict(theta, X[i])                   
        res[i] = (prediction - Y[i]) * (prediction - Y[i])  
    res = res - 2.0     
    return res

def gHat2(theta, X, Y):
    n = X.size          
    res = np.zeros(n)   
    for i in range(n):
        prediction = predict(theta, X[i])                   
        res[i] = (prediction - Y[i]) * (prediction - Y[i])  
    res = 1.25 - res   
    return res
```

```{python, echo = FALSE}
def leastSq(X, Y):
    X = np.expand_dims(X, axis=1) 
    Y = np.expand_dims(Y, axis=1) 
    reg = LinearRegression().fit(X, Y)
    theta0 = reg.intercept_[0]   
    theta1 = reg.coef_[0][0]     
    return np.array([theta0, theta1])
```

```{python, echo = FALSE}
def QSA(X, Y, gHats, deltas):

    candidateData_len = 0.40
    candidateData_X, safetyData_X, candidateData_Y, safetyData_Y = train_test_split(
      X, Y, test_size=1-candidateData_len, shuffle=False)
  
    candidateSolution = getCandidateSolution(candidateData_X, candidateData_Y, gHats, deltas, safetyData_X.size)

    passedSafety      = safetyTest(candidateSolution, safetyData_X, safetyData_Y, gHats, deltas)

    return [candidateSolution, passedSafety]
```

```{python, echo = FALSE}
def safetyTest(candidateSolution, safetyData_X, safetyData_Y, gHats, deltas):

    for i in range(len(gHats)):  
        g         = gHats[i]  
        delta     = deltas[i] 

    
        g_samples = g(candidateSolution, safetyData_X, safetyData_Y) 

        upperBound = ttestUpperBound(g_samples, delta) 

        if upperBound > 0.0: 
            return False

    return True
```

```{python, echo = FALSE}
def candidateObjective(thetaToEvaluate, candidateData_X, candidateData_Y, gHats, deltas, safetyDataSize): 

    result = fHat(thetaToEvaluate, candidateData_X, candidateData_Y)

    predictSafetyTest = True     
    
    for i in range(len(gHats)):  
        g         = gHats[i]       
        delta     = deltas[i]      

        g_samples = g(thetaToEvaluate, candidateData_X, candidateData_Y)

        upperBound = predictTTestUpperBound(g_samples, delta, safetyDataSize)

        if upperBound > 0.0:

            if predictSafetyTest:
                predictSafetyTest = False  

                result = -100000.0    

            result = result - upperBound

    return -result  
```

```{python, echo = FALSE}
def getCandidateSolution(candidateData_X, candidateData_Y, gHats, deltas, safetyDataSize):
  
    minimizer_method = 'Powell'
    minimizer_options={'disp': False}

    initialSolution = leastSq(candidateData_X, candidateData_Y)

    res = minimize(candidateObjective, x0=initialSolution, method=minimizer_method, options=minimizer_options, 
    args=(candidateData_X, candidateData_Y, gHats, deltas, safetyDataSize))

    return res.x
```

```{python, echo = FALSE}
main()
```

```{r fig3, fig.align='center', fig.cap="Quasi-Seldonian Linear Regression", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, echo = FALSE}
# find the y-hat values using the QSA
y_hat <- 0.6050927032 + 1.0201681981*x

# define the legend
colors <- c("OLS" = "red", "QSA" = "blue")

# plot the results
ggplot(data = seldonian_data, mapping = aes(x = x, y = y)) +
  geom_point(color = "lightblue") +
  geom_smooth(method = "lm", aes(color = "OLS")) +  
  geom_smooth(mapping = aes(x = x, y = y_hat, color = "QSA")) +
  labs(title = "Synthetic Data for Seldonian Linear Regression",
       x = "X",
       y = "Y",
       color = "Algorithm") +
  scale_color_manual(values = colors) +
  theme_minimal() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) 
```

To conclude this chapter, Section \@ref(exp) scales this process to repeatedly run a Quasi-Seldonian linear regression algorithm using different amounts of data and analyze the results. 

### Experimentation {#exp}

Consistent with the set-up in Section \@ref(toy), the aim of this experimentation is to assess three aspects of the defined quasi-Seldonian linear regression algorithm: performance loss, frequency of solutions, and frequency of undesirable behavior for varying sample sizes. 

```{python, echo = FALSE}
import timeit               
from numba import jit       
```

```{python, echo = FALSE}
bin_path = '/home/dasienga24/Statistics-Senior-Honors-Thesis/Thesis/index/experiment_results/chapter_2/'
```

```{python, echo = FALSE}
def run_experiments(worker_id, nWorkers, ms, numM, numTrials, mTest):
    
    # Results of the Seldonian algorithm runs
    ## The following code initializes an array filled with 0's. The resulting array will have numTrials rows (each trial) and numM columns (each data set size). Default is 0=False.
    
    seldonian_solutions_found = np.zeros((numTrials, numM)) # Stores whether a solution was found (1=True,0=False)
    seldonian_failures_g1     = np.zeros((numTrials, numM)) # Stores whether solution was unsafe, (1=True,0=False), for the 1st constraint, g_1
    seldonian_failures_g2     = np.zeros((numTrials, numM)) # Stores whether solution was unsafe, (1=True,0=False), for the 2nd constraint, g_2
    seldonian_fs              = np.zeros((numTrials, numM)) # Stores the primary objective values (fHat) if a solution was found
    
    # Results of the Least-Squares (LS) linear regression runs
    LS_solutions_found = np.ones((numTrials, numM))  # Stores whether a solution was found. These will all be true (=1)
    LS_failures_g1     = np.zeros((numTrials, numM)) # Stores whether solution was unsafe, (1=True,0=False), for the 1st constraint, g_1
    LS_failures_g2     = np.zeros((numTrials, numM)) # Stores whether solution was unsafe, (1=True,0=False), for the 2nd constraint, g_2
    LS_fs              = np.zeros((numTrials, numM)) # Stores the primary objective values (f) if a solution was found
    
    
    # Prepares file where experiment results will be saved
    experiment_number = worker_id
    outputFile = bin_path + 'results%d.npz' % experiment_number
    
    
    # Generate the data used to evaluate the primary objective and failure rates
    np.random.seed( (experiment_number+1) * 9999 )
    (testX, testY) = generateData(mTest) #we defined this above & mTest is the number of points in the test set 
    
    
    for trial in range(numTrials): #numTrials trials for each value of m 
        for (mIndex, m) in enumerate(ms): #different amounts of data to evaluate in each trial
            # Generate the training data, D
            base_seed         = (experiment_number * numTrials)+1
            np.random.seed(base_seed+trial) # done to obtain common random numbers for all values of m (all data set sizes) in the same trial but different numbers for different trials
            (trainX, trainY)  = generateData(m)
            
            # Run the Quasi-Seldonian algorithm
            (result, passedSafetyTest) = QSA(trainX, trainY, gHats, deltas)
            
            if passedSafetyTest:
                seldonian_solutions_found[trial, mIndex] = 1                        # A solution was found 
                trueMSE = -fHat(result, testX, testY)                               # Get the "true" mean squared error using the testData
                seldonian_failures_g1[trial, mIndex] = 1 if trueMSE > 2.0  else 0   # Check if the first behavioral constraint was violated
                seldonian_failures_g2[trial, mIndex] = 1 if trueMSE < 1.25 else 0   # Check if the second behavioral constraint was violated
                seldonian_fs[trial, mIndex] = -trueMSE                              # Store the "true" negative mean-squared error (goal of maximizing)
                #print(f"[(worker {worker_id}/{nWorkers}) Seldonian trial {trial+1}/{numTrials}, m {m}] A solution was found: [{result[0]:.10f}, {result[1]:.10f}]\tfHat over test data: {trueMSE:.10f}")
            else:
                seldonian_solutions_found[trial, mIndex] = 0             # A solution was not found
                seldonian_failures_g1[trial, mIndex]     = 0             # Returning NSF means the first constraint was not violated
                seldonian_failures_g2[trial, mIndex]     = 0             # Returning NSF means the second constraint was not violated
                seldonian_fs[trial, mIndex]              = None          # This value should not be used later. We use None and later remove the None values
                #print(f"[(worker {worker_id}/{nWorkers}) Seldonian trial {trial+1}/{numTrials}, m {m}] No solution found")

            # Run the Least Squares algorithm
            theta = leastSq(trainX, trainY)                              # Run least squares linear regression
            trueMSE = -fHat(theta, testX, testY)                         # Get the "true" mean squared error using the testData
            LS_failures_g1[trial, mIndex] = 1 if trueMSE > 2.0  else 0   # Check if the first behavioral constraint was violated
            LS_failures_g2[trial, mIndex] = 1 if trueMSE < 1.25 else 0   # Check if the second behavioral constraint was violated
            LS_fs[trial, mIndex] = -trueMSE                              # Store the "true" negative mean-squared error
            #print(f"[(worker {worker_id}/{nWorkers}) LeastSq trial {trial+1}/{numTrials}, m {m}] LS fHat over test data: {trueMSE:.10f}")
            
        
        
        
    # Save the arrays in a compressed format
    np.savez(outputFile, 
             ms=ms, 
             seldonian_solutions_found=seldonian_solutions_found,
             seldonian_fs=seldonian_fs, 
             seldonian_failures_g1=seldonian_failures_g1, 
             seldonian_failures_g2=seldonian_failures_g2,
             LS_solutions_found=LS_solutions_found,
             LS_fs=LS_fs,
             LS_failures_g1=LS_failures_g1,
             LS_failures_g2=LS_failures_g2)
```

```{python, echo = FALSE, cache = TRUE, message = FALSE, warning = FALSE}
# Create the behavioral constraints: each is a gHat function and a confidence level delta
gHats  = [gHat1, gHat2]
deltas = [0.1, 0.1]

nWorkers = 1  # Since we're not using Ray, we set the number of workers to 1 for sequential execution

# We will use different amounts of data, m. The different values of m will be stored in ms.
# These values correspond to the horizontal axis locations in all three plots we will make.
# We will use a logarithmic horizontal axis, so the amounts of data we use shouldn't be evenly spaced.
ms   = [2**i for i in range(5, 17)]  # ms = [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
numM = len(ms)
    
# How many trials should we average over?
numTrials = 5  # Reduced for demonstration purposes

# How much data should we generate to compute the estimates of the primary objective and behavioral constraint function values 
# that we call "ground truth"? Each candidate solution deemed safe, and identified using limited training data, will be evaluated 
# over this large number of points to check whether it is really safe, and to compute its "true" mean squared error.
mTest = ms[-1] * 100 # about 5,000,000 test samples

# Run experiments sequentially without parallelization
tic = timeit.default_timer()
for worker_id in range(1, nWorkers + 1):
    run_experiments(worker_id, nWorkers, ms, numM, numTrials, mTest)
toc = timeit.default_timer()
time_sequential = toc - tic # Elapsed time in seconds
```

```{python, echo = FALSE}
import csv 
import glob 
import re 
import matplotlib.pyplot as plt 
```

```{python, echo = FALSE}
bin_path = '/home/dasienga24/Statistics-Senior-Honors-Thesis/Thesis/index/experiment_results/chapter_2/'
csv_path = '/home/dasienga24/Statistics-Senior-Honors-Thesis/Thesis/index/experiment_results/chapter_2/csv/'
```

```{python, echo = FALSE}
def get_existing_experiment_numbers():
    result_files       = glob.glob(bin_path + 'results*.npz')
    experiment_numbers = [re.search('.*results([0-9]*).*', fn, re.IGNORECASE) for fn in result_files]
    experiment_numbers = [int(i.group(1)) for i in experiment_numbers]
    experiment_numbers.sort()
    return experiment_numbers
```

```{python, echo = FALSE}
def genFilename(n):
    return bin_path + 'results%d.npz' % n
```

```{python, echo = FALSE}
def addMoreResults(newFileId, ms, seldonian_solutions_found, seldonian_fs, seldonian_failures_g1, seldonian_failures_g2,
    LS_solutions_found, LS_fs, LS_failures_g1, LS_failures_g2):

    newFile = np.load(genFilename(newFileId))
    new_ms                        = newFile['ms']
    new_seldonian_solutions_found = newFile['seldonian_solutions_found']
    new_seldonian_fs              = newFile['seldonian_fs']
    new_seldonian_failures_g1     = newFile['seldonian_failures_g1']
    new_seldonian_failures_g2     = newFile['seldonian_failures_g2']
    new_LS_solutions_found        = newFile['LS_solutions_found']
    new_LS_fs                     = newFile['LS_fs']
    new_LS_failures_g1            = newFile['LS_failures_g1']
    new_LS_failures_g2            = newFile['LS_failures_g2']

    if type(ms)==type(None):
        return [new_ms, new_seldonian_solutions_found, new_seldonian_fs, new_seldonian_failures_g1, new_seldonian_failures_g2,
                new_LS_solutions_found, new_LS_fs, new_LS_failures_g1, new_LS_failures_g2]
    else:
        #ms                         = np.vstack([ms,                        new_ms])
        seldonian_solutions_found  = np.vstack([seldonian_solutions_found, new_seldonian_solutions_found])
        seldonian_fs               = np.vstack([seldonian_fs,              new_seldonian_fs])
        seldonian_failures_g1      = np.vstack([seldonian_failures_g1,     new_seldonian_failures_g1])
        seldonian_failures_g2      = np.vstack([seldonian_failures_g2,     new_seldonian_failures_g2])
        LS_solutions_found         = np.vstack([LS_solutions_found,        new_LS_solutions_found])
        LS_fs                      = np.vstack([LS_fs,                     new_LS_fs])
        LS_failures_g1             = np.vstack([LS_failures_g1,            new_LS_failures_g1])
        LS_failures_g2             = np.vstack([LS_failures_g2,            new_LS_failures_g2])

        return [ms, seldonian_solutions_found, seldonian_fs, seldonian_failures_g1, seldonian_failures_g2, 
                LS_solutions_found, LS_fs, LS_failures_g1, LS_failures_g2]

```

```{python, echo = FALSE}
def stderror(v):
    non_nan = np.count_nonzero(~np.isnan(v))        
    return np.nanstd(v, ddof=1) / np.sqrt(non_nan)
```

```{python, echo = FALSE}
def saveToCSV(ms, resultsQSA, resultsLS, filename):
    nCols = resultsQSA.shape[1]


    with open(filename, mode='w') as file:
        writer = csv.writer(file, delimiter=',')

        for col in range(nCols):

            cur_m          = ms[col]
            seldonian_data = resultsQSA[:,col]
            LS_data        = resultsLS[:,col]

            non_nan = np.count_nonzero(~np.isnan(seldonian_data))
            if non_nan > 0:
                seldonian_mean     = np.nanmean(seldonian_data)
                seldonian_stderror = stderror(seldonian_data)
            else:
                seldonian_mean     = 'NaN'
                seldonian_stderror = 'NaN'

            LS_mean     = np.mean(LS_data)
            LS_stderror = stderror(LS_data)

            writer.writerow([cur_m, seldonian_mean, seldonian_stderror, LS_mean, LS_stderror])
```

```{python, echo = FALSE}
def gather_results():
    ms                        = None
    seldonian_solutions_found = None
    seldonian_fs              = None
    seldonian_failures_g1     = None
    seldonian_failures_g2     = None
    LS_solutions_found        = None
    LS_fs                     = None
    LS_failures_g1            = None
    LS_failures_g2            = None

    experiment_numbers = get_existing_experiment_numbers()

    for file_idx in experiment_numbers:
        res = addMoreResults(file_idx, 
            ms, 
            seldonian_solutions_found, seldonian_fs, seldonian_failures_g1, seldonian_failures_g2, 
            LS_solutions_found, LS_fs, LS_failures_g1, LS_failures_g2)
        
        [ms, 
        seldonian_solutions_found, seldonian_fs, seldonian_failures_g1, seldonian_failures_g2, 
        LS_solutions_found, LS_fs, LS_failures_g1, LS_failures_g2] = res


    saveToCSV(ms,  -1*seldonian_fs,            -1*LS_fs,           csv_path+'fs.csv') # here, negative to return MSE rather than negative MSE
    saveToCSV(ms,  seldonian_solutions_found,  LS_solutions_found, csv_path+'solutions_found.csv')
    saveToCSV(ms,  seldonian_failures_g1,      LS_failures_g1,     csv_path+'failures_g1.csv')
    saveToCSV(ms,  seldonian_failures_g2,      LS_failures_g2,     csv_path+'failures_g2.csv')

```


```{python, echo = FALSE}
csv_path = '/home/dasienga24/Statistics-Senior-Honors-Thesis/Thesis/index/experiment_results/chapter_2/csv/'
img_path = '/home/dasienga24/Statistics-Senior-Honors-Thesis/Thesis/index/experiment_results/chapter_2/images/'
```

```{python, echo = FALSE}
def loadAndPlotResults(fileName, ylabel, output_file, is_yAxis_prob, legend_loc):
    file_ms, file_QSA, file_QSA_stderror, file_LS, file_LS_stderror = np.loadtxt(fileName, delimiter=',', unpack=True)

    fig = plt.figure()

    plt.xlim(min(file_ms), max(file_ms))
    plt.xlabel("Amount of data (m)", fontsize=16)
    plt.xscale('log')
    plt.xticks(fontsize=12)
    plt.ylabel(ylabel, fontsize=16)

    if is_yAxis_prob:
        plt.ylim(-0.1, 1.1)
    else:
        plt.ylim(-0.2, 2.2)
        plt.plot([1, 100000], [1.25, 1.25], ':k');
        plt.plot([1, 100000], [2.1,  2.1],  ':k');		

    plt.plot(     file_ms,     file_QSA, 'b-', linewidth=3, label='QSA')
    plt.errorbar( file_ms,     file_QSA, yerr=file_QSA_stderror, fmt='.k');
    plt.plot(     file_ms,     file_LS,  'r-', linewidth=3, label='LS')
    plt.errorbar( file_ms,     file_LS,  yerr=file_LS_stderror, fmt='.k');
    plt.legend(loc=legend_loc, fontsize=12)
    plt.tight_layout()

    plt.savefig(output_file)
    plt.show(block=False)
```

```{python, echo = FALSE, message = FALSE, warning = FALSE}
gather_results()
```

```{python fig4, fig.align='center', fig.cap="Performance Loss for Quasi-Seldonian Linear Regression Algorithms", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, echo = FALSE}
loadAndPlotResults(csv_path+'fs.csv', 'Mean Squared Error', img_path+'tutorial7MSE_py.png', False, 'lower right')
```

```{python fig5, fig.align='center', fig.cap="Probability of a Solution for Quasi-Seldonian Linear Regression Algorithms", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, echo = FALSE}
loadAndPlotResults(csv_path+'solutions_found.csv', 'Probability of Solution',   img_path+'tutorial7PrSoln_py.png',  True,  'best')
```

```{python fig6, fig.align='center', fig.cap="Satisfaction of Behavioral Constraints for Quasi-Seldonian Linear Regression Algorithms (#1)", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, echo = FALSE}
loadAndPlotResults(csv_path+'failures_g1.csv',     r'Probability of $g_1(a(D))>0$', img_path+'tutorial7PrFail1_py.png', True,  'best')
```

```{python fig7, fig.align='center', fig.cap="Satisfaction of Behavioral Constraints for Quasi-Seldonian Linear Regression Algorithms (#2)", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, echo = FALSE}
loadAndPlotResults(csv_path+'failures_g2.csv',     r'Probability of $g_2(a(D))>0$', img_path+'tutorial7PrFail2_py.png', True,  'best')
```

---- 

Work on the writw-up for the experimentation section!



\

- I also need to review my notes to fill in any missing pieces for the complete version of the Chapter. 

Add experimentation code to appendix B as well!

Revise and edit appendix B!



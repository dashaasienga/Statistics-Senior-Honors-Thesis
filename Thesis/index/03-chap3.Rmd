# Applying the Seldonian Framework in a Classification Setting {#chap-3}

```{r, include = FALSE}
library(mosaic)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
library(knitr)
library(kableExtra)
library(ggplot2)
library(GGally)
library(MASS)
library(gridExtra)
library(reshape2)
library(kableExtra)
library(pROC)
```

Chapter \@ref(chap-2) introduced the Seldonian framework, which offers probabilistic guarantees for satisfying defined behavioral constraints. Although impractical, the toy linear regression example demonstrated how Seldonian algorithms may be employed in a setting with a continuous real-valued response variable.

However, machine learning algorithms deal with classification problems in many practical applications. Applications range from risk assessment tools like COMPAS, discussed in Chapter \@ref(intro), to credit scoring and employment prediction algorithms, to name a few. However, deploying such algorithms raises significant ethical concerns, as discussed in Chapters \@ref(intro) and \@ref(chap-2), primarily regarding fairness and the potential reinforcement of discriminatory practices. Given the historical and social biases inherent in the data used to train these algorithms, there is a pressing need to assess their fairness and mitigate any potential harm they may cause disadvantaged groups.

To offer a path forward in addressing this issue, this chapter aims to apply the Seldonian framework to the COMPAS data set and assess its predictive outcomes compared to the COMPAS tool and logistic regression, a standard ML procedure. Specifically, the objective is to assess whether Seldonian approaches can produce fairer outcomes within the COMPAS setting,  drawing on some of the statistical definitions of fairness defined in Chapter \@ref(fairnessdefinitions). This chapter will present a framework that can be emulated in other classification problems where fairness is a concern. 


## The COMPAS Data Set

```{r, echo = FALSE}
# read in the data
compas_path <- "/home/dasienga24/Statistics-Senior-Honors-Thesis/Data Sets/COMPAS/compas_data.csv"
compasdata <- read.csv(compas_path)

# clean the data
compasdata <- compasdata %>%
  filter(decile_score > 0 & is_recid != -1 & days_b_screening_arrest >= -30 &
           days_b_screening_arrest <= 30) %>%
  mutate(days_b_screening_arrest = abs(days_b_screening_arrest))

# remove duplicates
clean_compasdata <- compasdata[-which(duplicated(compasdata$id)), ]
```

The COMPAS data set, obtained from the ProPublica Data Store [@compasdata], records information on defendants from Broward County, Florida, that were evaluated for the risk of recidivism by the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) tool in 2013 and 2014. A SQL query of the COMPAS database retrieved 12,160 observations (Appendix \@ref(appendix-c)). Of 29 variables returned, 6 were identified to be useful for predictive analysis: age, age category, sex, marital status, whether the defendant had a history of juvenile offenses or not, and the total number of prior offenses committed by the defendant. The response variable records whether or not a defendant had recommitted a crime within two years. Finally, the protected attribute, race, has six levels: African-American, Caucasian, Hispanic, Asian, Native American, and Other. 

Additionally, the COMPAS tool itself maps its raw scores into decile scores ranging from 1 to 10. The decile scores are directly associated with the risk of recidivism: scores between 1 and 4 are labeled as 'low' risk, between 5 and 7 as 'medium' risk, and between 8 and 10 as 'high risk'. After cleaning the data to address anomalies, improve the data quality, and remove duplicate observations, the data set size was reduced to 9387 observations. Section \@ref(descriptivestats) examines these variables in more detail and their relationships with each other.

Before proceeding with the analysis, it is crucial to consider that while the recidivism status, as recorded by the response variable, is treated as an objective gold standard truth of whether a defendant reoffended or not for the rest of this thesis, it is, in itself, likely biased by societal factors. For example, police officers are more likely to arrest Black defendants than White defendants for the same offense, and judges are more likely to convict Black defendants than White defendants for the same charges. While it is tangential to the theoretical underpinnings of the work in the proceeding sections, this context is, overall, important when applying mathematical, statistical, and computer science solutions to addressing algorithmic bias.

## Descriptive Statistics {#descriptivestats}

This section presents a holistic exploratory analysis of the COMPAS data set. The defendants' ages range from 18 to 96, with a median of 32 years and a mean of 34.75 years. There is a right skew, with the middle 50% of the defendants being between the ages of 25 and 42. Similarly, the variable recording the number of prior offenses has a significant right skew with a median of 1 offense and a mean of 3.02 offenses. The middle 50% of the defendants have committed between 0 and 4 offenses, and the defendant with the most prior offenses has committed 38 crimes. 

```{r ch3fig1, fig.align='center', fig.cap="Distribution of the COMPAS Continuous Variables", warning = FALSE, message = FALSE, fig.width = 6, fig.height = 3, include = FALSE}
g1 <- ggplot(data = clean_compasdata, mapping = aes(x = age)) +
  geom_histogram(fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(title = "Age",
       y = "Number of Defendants")

g2 <- ggplot(data = clean_compasdata, mapping = aes(x = priors_count)) +
  geom_histogram(fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(x = "priors",
       title = "Prior Offenses",
       y = "Number of Defendants")

grid.arrange(g1, g2, nrow = 1)
```


Of the 9387 total observations of defendants from Broward County, Florida, in 2013 and 2014, `r round(100*count(clean_compasdata$sex == "Male")/nrow(clean_compasdata),2)`% were male and the remaining `r round(100*count(clean_compasdata$sex == "Female")/nrow(clean_compasdata),2)`% were female. `r round(100*count(clean_compasdata$age_cat == "Less than 25")/nrow(clean_compasdata),2)`% are < 25 years old, `r round(100*count(clean_compasdata$age_cat == "25 - 45")/nrow(clean_compasdata),2)`% are between 25 and 45 years old, and 
`r round(100*count(clean_compasdata$age_cat == "Greater than 45")/nrow(clean_compasdata),2)`% are > 45 years old. The majority of defendants are single (`r round(100*count(clean_compasdata$marital_status == "Single")/nrow(clean_compasdata),2)`%), with the next largest categories being married (`r round(100*count(clean_compasdata$marital_status == "Married")/nrow(clean_compasdata),2)`%) and divorced (`r round(100*count(clean_compasdata$marital_status == "Divorced")/nrow(clean_compasdata),2)`%). The other levels were significant other, separated, unknown, and widowed, respectively. Finally, `r round(100*count(clean_compasdata$juv_offense == 0)/nrow(clean_compasdata),2)`% of defendants had no record of juvenile offenses. The remaining `r round(100*count(clean_compasdata$juv_offense == 1)/nrow(clean_compasdata),2)`% ranged from having 1 offense to 21 offenses on record, with a median of 1, a mean of 1.96, and the middle 50% recording 1 or 2 offenses.  


```{r, echo = FALSE}
clean_compasdata <- clean_compasdata %>%
  mutate(juv_offense_count = juv_fel_count + juv_misd_count + juv_other_count,
         juv_offense = ifelse(juv_offense_count == 0, 0, 1))
```


```{r ch3fig2, fig.align='center', fig.cap="Distribution of the COMPAS Categorical Variables", warning = FALSE, message = FALSE, fig.width = 6, fig.height = 6, include = FALSE}
g3 <- ggplot(data = clean_compasdata, mapping = aes(x = sex)) +
  geom_bar(fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(title = "Sex",
       y = "Number of Defendants")

order <- c("Less than 25", "25 - 45", "Greater than 45")

g4 <- ggplot(data = clean_compasdata, mapping = aes(x = age_cat)) +
  geom_bar(fill = "lightblue", color = "black") +
  theme_minimal() +
  scale_x_discrete(limits = order) +
  labs(x = "Age Category",
       title = "Age Categories",
       y = "Number of Defendants")

g5 <- ggplot(data = clean_compasdata, mapping = aes(x = marital_status)) +
  geom_bar(fill = "lightblue", color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 25, vjust = 1.2, hjust=1)) +
  labs(x = "Marital Status",
       title = "Marital Status",
       y = "Number of Defendants") 


g6 <- clean_compasdata %>%
  mutate(juv_offense = ifelse(juv_offense == 0, "No", "Yes")) %>%
  ggplot(mapping = aes(x = juv_offense)) +
  geom_bar(fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(x = "Committed a Juvenile Offense",
       title = "Juvenile Offense Record",
       y = "Number of Defendants")

grid.arrange(g3, g4, g6, g5, ncol = 2, nrow = 2)

```


### Response Variable {#response}

The response variable records whether or not a defendant recommitted any crime within two years. About two-thirds (n = 6199) of the defendants did not recommit a crime within two years, while about one-third (n = 3188) did. The different proportion of observations in each level indicates class imbalance, which often affects the performance of machine learning classification algorithms. Given the class imbalance, analyzing performance relative to the classes will be important when assessing model performance in the proceeding sections. 

```{r ch3fig3, fig.align='center', fig.cap="Distribution of the COMPAS Response Variable: Recidivism", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 2.5, include = FALSE}
clean_compasdata %>%
mutate(is_recid = ifelse(is_recid == 0, "No", "Yes")) %>%
ggplot(mapping = aes(x = is_recid)) +
  geom_bar(fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(title = "Recidivism",
       x = "Recommitted a Crime Within 2 Years",
       y = "Number of Defendants")
```

### Protected Attribute {#protectedattribute}

Finally, the protected attribute in this analysis is race. Most of the defendants are African-American (`r round(100*count(clean_compasdata$race == "African-American")/nrow(clean_compasdata),2)`%) and Caucasian (`r round(100*count(clean_compasdata$race == "Caucasian")/nrow(clean_compasdata),2)`%), with only `r round(100*count(clean_compasdata$race == "Hispanic")/nrow(clean_compasdata),2)`% Hispanic, `r round(100*count(clean_compasdata$race == "Asian")/nrow(clean_compasdata),2)`% Asian, and finally, `r round(100*count(clean_compasdata$race == "Native American")/nrow(clean_compasdata),2)`% Native American. The remaining `r round(100*count(clean_compasdata$race == "Other")/nrow(clean_compasdata),2)`% of defendants identify as 'Other'. 


```{r ch3fig4, fig.align='center', fig.cap="Distribution of the COMPAS Protected Attribute: Race", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 2.5, include = FALSE}
ggplot(data = clean_compasdata, mapping = aes(x = race)) +
  geom_bar(fill = "lightblue", color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 25, vjust = 1.2, hjust=1)) +
  labs(title = "Race",
       y = "Number of Defendants")
```

### Associations Between the Predictors and Response {#bivariateanalysis}

With a thorough understanding of the variables, this section examines the relationship between the predictive variables and the response variable, recidivism.

Defendants who recidivated tended to be younger than than those who didn't (median age 29 versus 33, mean age 32 versus 36, respectively; Figure \@ref(fig:ch3fig5)A). Defendants who recidivated also tended to have more non-juvenile prior offenses than those who didn't recidivate (median prior offenses 3 versus 1, mean prior offenses 4.7 versus 2.2, respectively; Figure \@ref(fig:ch3fig5)B).

```{r ch3fig5, fig.align='center', fig.cap="Distribution of Age (panel A) and Number of Prior Offenses (panel B) by Recidivism Status among 9,387 Defandants in Broward County Florida, 2013-2014", warning = FALSE, message = FALSE, fig.width = 6, fig.height = 3, echo = FALSE}

g7 <- clean_compasdata %>%
  mutate(is_recid = ifelse(is_recid == 0, "No", "Yes")) %>%
  ggplot(mapping = aes(x = is_recid, y = age)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "(A)",
       x = "Recidivism",
       y = "Age")

g8 <- clean_compasdata %>%
  mutate(is_recid = ifelse(is_recid == 0, "No", "Yes")) %>%
  ggplot(mapping = aes(x = is_recid, y = priors_count)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "(B)",
       x = "Recidivism",
       y = "Prior Offenses")

grid.arrange(g7, g8, nrow = 1)
```

Sex and marital status were similar between defendants who did and did not recidivate. Additionally, while most defendants do not have juvenile offenses, the proportion of those who do not to those who do is much smaller for defendants who re-offend in comparison to those who do not. Figure \@ref(fig:ch3fig6) displays the significant relationships.

```{r ch3fig6, fig.align='center', fig.cap="Conditional Distribution of Age (panel A) and Juvenile Offense (panel B) by Recidivism Status among 9,387 Defandants in Broward County Florida, 2013-2014", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 4.5, echo = FALSE}
g9 <- ggplot(data = clean_compasdata, mapping = aes(x = sex, fill = sex)) +
  geom_bar() +
  theme_minimal() +
  facet_wrap(~is_recid) +
  labs(title = "Recidivism by Sex",
       y = "Number of Defendants") 

order <- c("Less than 25", "25 - 45", "Greater than 45")

g10 <- ggplot(data = clean_compasdata, 
       mapping = aes(x = age_cat, fill = age_cat)) +
  geom_bar() +
  theme_minimal() +
  facet_wrap(~is_recid) +
  labs(title = "Recidivism by Age Categories",
       x = "Age Category",
       fill = "Age Category",
       y = "Number of Defendants") +
  theme(axis.text.x = element_text(angle = 25, vjust = 1.2, hjust=1)) +
  scale_x_discrete(limits = order) 

g11 <- ggplot(data = clean_compasdata, 
       mapping = aes(x = marital_status, fill = marital_status)) +
  geom_bar() +
  theme_minimal() +
  facet_wrap(~is_recid) +
  labs(title = "Recidivism by Marital Status",
       x = "Marital Status",
       fill = "Marital Status",
       y = "Number of Defendants") +
  theme(axis.text.x = element_text(angle = 25, vjust = 1.2, hjust=1))

g12 <- clean_compasdata %>%
  mutate(juv_offense = ifelse(juv_offense == 0, "No", "Yes")) %>%
  ggplot(mapping = aes(x = juv_offense, fill = juv_offense)) +
  geom_bar() +
  theme_minimal() +
  facet_wrap(~is_recid) +
  labs(title = "Recidivism by Juvenile Offense",
       x = "Juvenile Offense",
       fill = "Juvenile Offense",
       y = "Number of Defendants") 


new1 <- ggplot(data = clean_compasdata, 
               mapping = aes(x = as.factor(is_recid), fill = age_cat)) +
  geom_bar(position = "fill") +
  theme_minimal() +
  labs(title = "(A)",
       x = "Recidivism Status",
       fill = "Age Category",
       y = "Percent") +
  scale_fill_viridis_d(breaks = c("Less than 25", "25 - 45", "Greater than 45")) 
  
new2 <- clean_compasdata %>%
  mutate(juv_offense = ifelse(juv_offense == 0, "No", "Yes"),
         juv_offense = factor(juv_offense, levels = c("Yes", "No"))) %>%
  ggplot(mapping = aes(x = as.factor(is_recid), fill = juv_offense)) +
  geom_bar(position = "fill") +
  theme_minimal() +
  labs(title = "(B)",
       x = "Recidivism Status",
       fill = "Juvenile Offense",
       y = "Percent") 

grid.arrange(new1, new2, nrow = 2)
```

### Multivariate Analysis

```{r, echo = FALSE}
compas_final <- clean_compasdata %>%
  dplyr::select(c(race, sex, age, age_cat, marital_status, 
                  juv_offense, priors_count,
                  decile_score, is_recid))
```


As detailed in Section \@ref(bivariateanalysis), some predictive variables have a covariate relationship with the response variable, recidivism. A scatterplot matrix examining the relationship between the continuous variables, age and prior offenses, revealed weak correlations (Spearman's rho: $\rho = 0.12$) and nonlinear relationships. There are no significant concerns for multicollinearity. Figure \@ref(fig:ch3fig7) illustrates this using Spearman's correlation. In addition, the correlation matrix incorporates the COMPAS tool decile scores to examine the predictive relationship between the continuous variables and the COMPAS tool results. Spearman's correlation revealed a moderate relationship of $\rho = -0.44$ and $\rho = 0.44$ for age and prior offenses, respectively.

```{r ch3fig7, fig.align='center', fig.cap="Spearman's Correlation Matrix for Age, Number of Prior Offenses, and the COMPAS Tool Decile Scores", warning = FALSE, message = FALSE, fig.width = 4.5, fig.height = 3, echo = FALSE}
mycordata3 <- compas_final %>%
  dplyr::rename("Age" = age,
         "Priors" = priors_count,
         "Decile Scores" = decile_score) %>%
  dplyr::select("Age", "Priors", "Decile Scores")

mycors <- round(cor(mycordata3, method = "spearman"),2)
mycorplot <- melt(mycors)

ggplot(data = mycorplot, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  labs(x = "",
       y = "",
       title = "Spearman's Correlation Matrix") +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 0,
    limit = c(-1, 1),
    space = "Lab",
    name = "Spearman\nCorrelation"
  ) +
  geom_text(aes(Var2, Var1, label = value),
            color = "black",
            size = 3) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, vjust = 1, hjust = 1))

```

With a thorough understanding of the variables, Section \@ref(fairnessanalysis) analyzes the data set and the COMPAS tool decile scores with a focus on fairness and an aim to examine the fairness concerns discussed in Chapters \@ref(intro) and \@ref(chap-2).

## Fairness and Demographic Analysis {#fairnessanalysis}

Chapter \@ref(algbias) introduced algorithmic bias as a situation when an algorithm’s decisions are skewed towards a particular group of people, either positively or negatively. With race as the protected attribute, this section aims to examine the COMPAS tool results, the underlying proxy relationships between the variables and the sensitive attribute, race, and create a table similar to the one in Figure \@ref(fig:compas1), which highlights the discrepancy in false positive and false negative rates of the COMPAS tool for Black and White defendants. 

### COMPAS Tool Analysis {#comptoolanalysis}

Recall that COMPAS decile scores of 1 to 4 are mapped as 'low' risk, 5 to 7 as 'medium' risk, and 8 to 10 as 'high' risk. The median decile score for the entire data set is four, and Figure \@ref(fig:ch3fig8) illustrates that the COMPAS tool classifies more than half of the defendants as low risk. In particular, the tool classifies 5370 as low risk and 1677 as high risk, with the remaining 2340 as medium risk. These predictions align with expectations since most defendants did not recommit a crime within the two-year time window, as observed in Section \@ref(response). 

```{r ch3fig8, fig.align='center', fig.cap="Distribution of COMPAS Tool Decile Scores among 9,387 Defandants in Broward County Florida, 2013-2014", warning = FALSE, message = FALSE, fig.width = 6, fig.height = 3, echo = FALSE}

order <- c("Low", "Medium", "High")

g14 <- ggplot(data = clean_compasdata, mapping = aes(x = score_text)) +
  geom_bar() +
  theme_minimal() +
  scale_x_discrete(limits = order) +
  labs(x = "COMPAS Risk Prediction",
       title = "COMPAS Risk Predictions in the Data Set",
       y = "Number of Defendants")

g15 <- ggplot(data = clean_compasdata, mapping = aes(x = as.factor(decile_score),
                                                     fill = score_text)) +
  geom_bar() +
  theme_minimal() +
  labs(x = "COMPAS Decile Score",
       title = "Decile Scores in the COMPAS Data Set",
       y = "Number of Defendants",
       fill = "COMPAS Risk Prediction") +
  scale_fill_manual(values = c("Low" = "darkgreen",
                               "Medium" = "orange",
                               "High" = "red"),
                    breaks = c("Low", "Medium", "High")) 

grid.arrange(g15)
```

However, when these scores are broken down by whether the defendant reoffended within two years, it is revealed that the COMPAS tool performs poorly in classifying participants who recidivate. Such participants are classified almost equally into the three risk categories: low, medium, and high. Furthermore, while most defendants who do not reoffend within two years are classified as low risk, a significant number of them are classified as 'medium' and 'high' risk. The decile scores of defendants who recidivate and those who do not also range from 1 to 10, although the median decile score is 6 for the former group and 3 for the latter group. Generally, these results raise concerns about the COMPAS tool's predictive performance. 

```{r ch3fig9, fig.align='center', fig.cap="Distribution of COMPAS Tool Risk Scores among 9,387 Defandants in Broward County Florida, 2013-2014", warning = FALSE, message = FALSE, fig.width = 5, fig.height = 2.5, echo = FALSE}
order <- c("Low", "Medium", "High")

clean_compasdata %>%
  mutate(is_recid = ifelse(is_recid == 0, "No", "Yes"),
         score_text = factor(score_text, levels = c("High", "Medium", "Low"))) %>%
  ggplot(mapping = aes(x = is_recid, fill = score_text)) +
  geom_bar(position = "fill") +
  theme_minimal() +
  labs(x = "Recidivism Status",
       fill = "COMPAS Risk Score",
       y = "Percent")  +
  scale_fill_manual(values = c("Low" = "darkgreen",
                               "Medium" = "orange",
                               "High" = "red"),
                    breaks = c("Low", "Medium", "High")) 
```


A breakdown by race, the protected attribute, will allow for further analysis of the performance of the COMPAS tool. Before that, converting this into a binary prediction problem will make analysis much more tractable. Decile scores of 1 to 5 will be mapped as 'lower' risk, while those ranging from 6 to 10 will be mapped as 'higher' risk. 

```{r, echo = FALSE}
compas <- compas_final %>%
  mutate(risk = ifelse(decile_score %in% c(1, 2, 3, 4, 5),'Lower','Higher'))
```


Table \@ref(tab:ch3table1) displays the confusion matrix of the COMPAS tool's results on this data set, which has `r nrow(compas)` total observations, with this binary definition of risk. The matrix reveals that the model has an overall accuracy of 66.61% on this data set. However, 66.04% of defendants do not recommit a crime within two years, as observed in Section \@ref(response). Therefore, a blind non-informative model that classifies every defendant into the negative class would attain an accuracy of 66%, suggesting that the COMPAS tool's 66.61% accuracy is a negligible improvement. 

Notice, furthermore, that the model struggles more in predicting whether defendants will reoffend than in predicting whether defendants will not reoffend. This imbalance in error rates is expected because of the class imbalance observed when performing exploratory data analysis in Section \@ref(descriptivestats) -- most defendants do not reoffend, so the model maximizes performance for those defendants. In terms of proportions, 49.25% of defendants who reoffended are incorrectly labeled as lower risk (almost equivalent to a flip of a coin), compared to 25.23% of defendants who did not reoffend but are incorrectly labeled as higher risk. This also raises the question of what type of prediction is more important: the risk of recidivism or the risk of non-recidivism. Is wrongly attributing a defendant as higher risk or wrongly attributing a defendant as lower risk worse for society?


```{r ch3table1, warning = FALSE, message = FALSE, echo = FALSE}
compas %>%
  dplyr::select(risk, is_recid) %>%
  rename("Risk" = risk) %>%
  group_by(Risk) %>%
  summarise("Reoffended" = count(is_recid == 1),
            "Did Not Reoffend" = count(is_recid == 0)) %>%
  kable(digits = 2,
        caption = "The Percent of Defendants who were Labeled Higher/Lower Risk by the COMPAS Tool Stratified by Recidivism Status among 9,387 Defandants in Broward County Florida, 2013-2014",
        booktabs = TRUE)
```


$\\$

While the confusion matrix in Table \@ref(tab:ch3table1) relays information on what types of errors the COMPAS tool tends to make and raises questions about the implications of that, Table \@ref(tab:ch3table2) breaks that down further by race for a more granular assessment. While the overall FPR is 25.3%, it is much higher for Black defendants (37.71%) and much lower for White defendants (16.34%). Similarly, while the overall FNR is 49.25%, it is much higher for White defendants (62.26%) and much lower for Black defendants (39.01%) (Table \@ref(tab:ch3table2)). The tool is more than twice as likely to classify a Black defendant who did not reoffend as higher risk compared to a White defendant. It makes the opposite mistake, where it is 1.6 times more likely to classify a White defendant who reoffended as lower risk compared to a Black defendant. This discrepancy aligns with ProPublica's findings in Figure \@ref(fig:compas1) and is alarming given that race was not included in the model. 

Including the other races reveals that Asian defendants who did not reoffend were the least likely to be labeled as higher risk – Black defendants were the most likely. Conversely, the "Other" group who reoffended, followed by White defendants, were the most likely to be labeled as lower risk – Native Americans were the least likely. However, it is essential to consider the few observations in both the Asian (n = 48) and Native American groups (n = 27), as detailed in Section \@ref(protectedattribute).

The analysis in this section provides evidence for disparities with favorable COMPAS outcomes for White and Asian defendants and unfavorable outcomes for Black and Native American defendants. To visualize these results, Figure \@ref(fig:ch3fig11) displays the distribution of the decile scores for the two most populous races in the data set. While there is a similar distribution of recidivism for all races with most defendants not recidivating, Black defendants' decile scores are distributed almost uniformly among the ten decile scores. In contrast, the White defendants' decile scores have a significant right skew, with most observations in lower decile scores. This further emphasizes the racial disparity in employing these risk scores in judicial decisions and the present algorithmic bias.


```{r ch3table2, warning = FALSE, message = FALSE, echo = FALSE}
compas %>%
  dplyr::select(race, risk, is_recid) %>%
  rename("Risk" = risk,
         "Race" = race) %>%
  group_by(Race, is_recid) %>%
  mutate(Total = n()) %>%
  group_by(Risk, Race, Total) %>%
  summarise("Reoffended" = count(is_recid == 1),
            "Did Not Reoffend" = count(is_recid == 0)) %>%
  pivot_longer(cols = c("Reoffended", "Did Not Reoffend"),
               names_to = "Recidivism") %>%
  pivot_wider(
    id_cols = c("Risk", "Recidivism", "Total"),
    names_from = "Race",
    values_from = value
  ) %>%
  rename("Black" = `African-American`,
         "White" = `Caucasian`) %>%
  mutate(Black = round(100 * Black / Total, 2),
         White = round(100 * White / Total, 2),
         Hispanic = round(100 * Hispanic / Total, 2),
         Asian = round(100 * Asian / Total, 2),
         `Native American` = round(100 * `Native American` / Total, 2),
         Other = round(100 * Other / Total, 2)) %>%
  dplyr::select(-Total) %>%
  group_by(Recidivism, Risk) %>%
  summarize(Black = max(Black, na.rm = TRUE),
            White = max(White, na.rm = TRUE),
            Hispanic = max(Hispanic, na.rm = TRUE),
            Asian = max(Asian, na.rm = TRUE),
            `Native American` = max(`Native American`, na.rm = TRUE),
            Other = max(Other, na.rm = TRUE)) %>%
  filter((Risk == "Higher" & Recidivism == "Did Not Reoffend") |
           (Risk == "Lower" & Recidivism == "Reoffended") 
  ) %>%
  rename("Recidivism Status" = Recidivism,
         "Predicted Risk" = Risk) %>%
  kable(digits = 2,
        caption = "The Percent of Defendants who were Incorrectly Labeled Higher/Lower Risk by the COMPAS Tool Stratified by Recidivism Status and Race among 9,387 Defandants in Broward County Florida, 2013-2014",
        booktabs = TRUE)
```


```{r ch3fig11, fig.align='center', fig.cap="Distribution of COMPAS Tool Decile Scores Stratified by Race among 9,387 Defandants in Broward County Florida, 2013-2014", warning = FALSE, message = FALSE, fig.width = 6, fig.height = 2.5, echo = FALSE}
compas %>%
  filter(race %in% c("African-American", "Caucasian")) %>%
  mutate(race = ifelse(race == "African-American", "Black", "White"),
         is_recid = ifelse(is_recid == 0, "No", "Yes"),
         is_recid = factor(is_recid, levels = c("Yes", "No"))) %>%
ggplot(mapping = aes(x = as.factor(decile_score), fill = as.factor(is_recid))) +
  geom_bar() +
  theme_minimal() +
  facet_wrap(~race, ncol = 2) + labs(
    title = "Decile Scores by Race",
    x = "Decile Scores",
    y = "Number of Defendants",
    fill = "Recidivism Status")
```


### Proxy Relationships 

Section \@ref(comptoolanalysis) revealed that the predictions of the COMPAS tool exhibit significant racial discrepancies. Yet, the COMPAS tool is a race-blind model. Race was not included as a variable, so how could a model result in such racially distinct outcomes? To answer this question, this section analyzes the relationship between race and the predictive variables to examine how much information regarding a defendant's race is incorporated into the model via other variables.

There are more male than female defendants for all races, and most defendants are single. However, African-American defendants tend to be, on average, the youngest compared to all the other races. Asian defendants, followed by Caucasian defendants, tend to be the oldest. Nevertheless, there is considerable overlap among all the races, and Figure \@ref(fig:ch3fig10) visualizes the relationships. In looking at the age categories by race, more African-American defendants are < 25 than those who are > 45. The converse is true for Caucasians, with more defendants that are > 45 in comparison to those < 25. These distributional differences illustrate that there is some relationship between age and race in this data set, particularly for Black versus White defendants. 

```{r ch3fig10, fig.align='center', fig.cap="Distribution of COMPAS Tool Proxy Variables Stratified by Race among 9,387 Defandants in Broward County Florida, 2013-2014", warning = FALSE, message = FALSE, fig.width = 6, fig.height = 8, echo = FALSE}
g18 <- ggplot(data = compas_final, 
       mapping = aes(x = as.factor(race), y = age)) +
  geom_boxplot() +
  theme_minimal() +
  labs(x = "Race",
       y = "Age")

order <- c("Less than 25", "25 - 45", "Greater than 45")
  
g19 <- compas_final %>%
  filter(race %in% c("Caucasian", "African-American")) %>%
  ggplot(mapping = aes(x = age_cat, fill = age_cat)) +
  geom_bar() +
  theme_minimal() +
  facet_wrap(~race) +
  labs(x = "Age Category",
       fill = "Age Category",
       y = "Number of Defendants") +
  theme(axis.text.x = element_text(angle = 25, vjust = 1.2, hjust=1)) +
  scale_x_discrete(limits = order) +
  scale_fill_viridis_d(breaks = c("Less than 25", "25 - 45", "Greater than 45"))

g20 <- ggplot(data = compas_final, 
       mapping = aes(x = as.factor(race), y = priors_count)) +
  geom_boxplot() +
  theme_minimal() +
  labs(x = "Race",
       y = "Number of Prior Offenses")

grid.arrange(g18, g19, g20, nrow = 3)
```


Additionally, African-American defendants have the most prior offenses, on average, followed by their Native-American counterparts. When compared with Caucasian defendants, African Americans have almost twice as many prior offenses, suggesting a strong proxy relationship between race and prior offenses. Asian defendants have the least prior offenses. This is an important result that illustrates how a system that predisposes certain races to prison can perpetuate that discriminatory trend by using those same variables to predict the risk of committing another crime. The boxplot in Figure \@ref(fig:ch3fig10) helps to visualize this relationship more clearly.

This section illustrates that the protected attribute, race ($A$), has proxy relationships with some predictor variables ($X$). Even a group-blind classifier will not be entirely blind to race because of the correlations present and the information it gains about race from the proxy variables.

```{r ch3fig13, fig.align='center', fig.cap="Distribution of Recidivism Prevalence Stratified by Race among 9,387 Defandants in Broward County Florida, 2013-2014", warning = FALSE, message = FALSE, fig.width = 6, fig.height = 2.5, echo = FALSE}
compas_final %>%
  dplyr::select(c(race, is_recid)) %>%
  group_by(race, is_recid) %>%
  summarise(num_defendants = n()) %>%
  mutate(race = factor(race, levels = c("African-American", "Caucasian", "Hispanic",
                                        "Other", "Native American", "Asian")),
         is_recid = ifelse(is_recid == 0, "No", "Yes"),
         is_recid = factor(is_recid, levels = c("Yes", "No"))) %>%
  ggplot(mapping = aes(x = race, y = num_defendants, fill = as.factor(is_recid))) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(x = "Race",
       y = "Number of Defendants",
       title = "Recidivism Prevalence by Race",
       fill = "Recidivism Status") +
  theme(axis.text.x = element_text(angle = 25, vjust = 1.2, hjust=1)) 
```

Most defendants do not recommit another crime, even when broken down by race as visualized in Figure \@ref(fig:ch3fig13). Because the class imbalance is in the same direction, a 'fair' model should not misclassify defendants in different directions based on race. However, the nature of the relationship between race and the predictor variables results in discriminatory and unfair outcomes, as elucidated in Section \@ref(comptoolanalysis). 

Before employing the Seldonian framework on this data set, Section \@ref(logreg) fits a logistic regression to assess how similarly the COMPAS tool performs to a standard ML procedure. 

## Logistic Regression {#logreg}

Logistic regression is a statistical generalized linear model (GLM) specifically designed to predict dichotomous/ binary outcomes. In this case, logistic regression was used to model the probability of a defendant re-committing a crime within two years in Broward County, Florida, using the COMPAS data set. With a cutoff of 0.5, the resulting probabilities were divided into two bins: lower risk ($p < 0.5$) and higher risk ($p >= 0.5$). Given that logistic regression is one of the most widely used classification algorithms, this analysis will provide insights into how state-of-the-art traditional algorithms that follow the standard ML procedure described in Chapter \@ref(standardml) and do not consider fairness guarantees may perform on this data set.


### Fitting the Logistic Regression Model

Recall that if every observation were classified in the majority class, an accuracy of 66% would be expected. This is a benchmark for the race-blind logistic regression model implemented in this section. The model will be trained on 70% of the data and evaluated on the remaining 30%. Only the five predictors (sex, age, marital status, juvenile offense, and prior offenses) will be fit to predict recidivism, the R code for which is displayed in Appendix \@ref(appendix-d).

The accuracy was 70.2% on the training set, which is ~3% higher than the COMPAS tool's predictions and suggests that ~30% of defendants are misclassified. Overall accuracy was consistent at 70.1% when evaluated on the testing set, indicating that the model did not over-fit on the training set and had good generalization performance. However, the ROC curve on Figure \@ref(fig:ch3fig12) indicates concerns about the model's sensitivity $(1 - FNR)$ and specificity $(1 - FPR)$. The diagonal line shows how the model would perform with random predictions. Curves that budge closer to the top left are preferred because those types of curves maximize the area under the curve (AUC), and the sensitivity and specificity of the model are closer to 100%. However, the AUC of this model is 68.8%. 

```{r, echo = FALSE, warning = FALSE, message = FALSE}
# set seed
set.seed(123)

# drop missing observations
compas <- tidyr::drop_na(compas) 

# train and test split
n <- nrow(compas)
train_index <- sample(1:n, 0.70 * n) 
test_index <- setdiff(1:n, train_index)
train <- compas[train_index, ]
test <- compas[test_index, ]

# fit the logistic regression model on identified predictors
glm2 <- glm(is_recid ~ sex + age + age_cat + marital_status +
              juv_offense + priors_count,
            data = train,
            family = binomial(logit))

# obtain the binary predictions on train set
glm2augment <- glm2 %>% 
  broom::augment(type.predict = "response")
glm2augment <- mutate(glm2augment, binprediction = round(.fitted, 0)) 

# obtain the binary predictions on test set 
preds <- predict(glm2, newdata=test, type="response")
test2 <- test %>% 
  mutate(preds = preds,
         prediction = round(preds, 0)) 

# obtain the ROC curve
roccurve1 <- with(test, roc(is_recid ~ preds))
```


```{r ch3fig12, fig.align='center', fig.cap="COMPAS Logistic Regression Receiver Operating Characteristic (ROC) Curve", warning = FALSE, message = FALSE, fig.width = 3.5, fig.height = 3, echo = FALSE}
plot(roccurve1)
```

### Evaluating the Equality of Odds  

Despite the improved accuracy, examining the direction of these error rates and performing a demographic analysis by race to assess the model’s ‘fairness’ along racial lines reveals the same discrepancies observed in the COMPAS tool results. 

Table \@ref(tab:ch3table3) displays the overall false positive and false negative rates. As expected, the model performs better in classifying defendants who do not reoffend than those who do since that is the majority class. When evaluated on the test set, 91.05% of defendants who did not reoffend are correctly classified as low-risk. Thus, only 8.95% of participants who do not reoffend are incorrectly classified as high-risk. This is a lower FPR than COMPAS. However, only 29% of defendants who reoffended are correctly classified as high-risk. Thus, 71% of defendants who reoffended are incorrectly classified as low-risk. This is a higher FNR than COMPAS.

Table \@ref(tab:ch3table4) further breaks these results down, focusing on Black and White defendants. While the overall FPR for the model is 8.95%, notice that the FPR for Black defendants is 13.93%, compared to only 5.09% for White defendants. Similar to the COMPAS tool, Black defendants who do not reoffend are incorrectly misclassified as high risk at twice the rate that White defendants are. On the flip side, while the overall FNR for the model is 71%, notice that the FNR for Black defendants is 60.82%, compared to 86.17% for White defendants. Similar to the COMPAS tool, the logistic regression makes the opposite mistake in predicting recidivism for Black v White defendants, with White defendants being more likely to be incorrectly classified as low risk than their Black counterparts.

These results serve to highlight the real danger with using standard ML procedures, even when the sensitive variable itself is not included. These models have potential to perpetuate, and even introduce, harmful and discriminatory practices as observed in this Chapter. Although the details of Northepointe's COMPAS algorithm are kept secret, it's clear that traditional algorithms like logistic regression lead to comparable outcomes. In fact, a probability cutoff of $p = 0.34$, the probability of being in the positive class in this data set, on the logistic regression yielded the same accuracy ($66.7$%) as the COMPAS tool. Additionally, comparing the COMPAS decile scores to the logistic regression (LR) results reveals that the median decile score is 8 in the high-risk LR prediction and 3 in the low-risk LR prediction, further highlighting the similarity of these results. The next section uses the logistic regression model as a starting point, but places fairness constraints to enforce equality of odds for Black and White defendants.

```{r ch3table3, warning = FALSE, message = FALSE, echo = FALSE}
test2 <- test2 %>%
  mutate(pred_risk = ifelse(prediction == 0, 'Low', 'High'))

test2 %>%
  dplyr::select(pred_risk, is_recid) %>%
  rename("Risk" = pred_risk) %>%
  group_by(is_recid) %>%
  mutate(Total = n()) %>%
  group_by(Risk, Total) %>%
  summarise("Reoffended" = count(is_recid == 1),
            "Did Not Reoffend" = count(is_recid == 0)) %>%
  mutate(Reoffended = round(100 * Reoffended / Total, 2),
         `Did Not Reoffend` = round(100 * `Did Not Reoffend` / Total, 2)) %>%
  dplyr::select(-Total) %>%
  group_by(Risk) %>%
  summarize(Reoffended = max(Reoffended, na.rm = TRUE),
            `Did Not Reoffend` = max(`Did Not Reoffend`, na.rm = TRUE)) %>%
  kable(digits = 2,
        booktabs = TRUE,
        caption = "COMPAS Logistic Regression Error Rates (Percentage)")
```



```{r ch3table4, warning = FALSE, message = FALSE, echo = FALSE}
test2 %>%
  filter(race %in% c("African-American", "Caucasian")) %>%
  dplyr::select(race, pred_risk, is_recid) %>%
  rename("Risk" = pred_risk,
         "Race" = race) %>%
  group_by(Race, is_recid) %>%
  mutate(Total = n()) %>%
  group_by(Risk, Race, Total) %>%
  summarise("Reoffended" = count(is_recid == 1),
            "Did Not Reoffend" = count(is_recid == 0)) %>%
  pivot_longer(cols = c("Reoffended", "Did Not Reoffend"),
               names_to = "Recidivism") %>%
  pivot_wider(
    id_cols = c("Risk", "Recidivism", "Total"),
    names_from = "Race",
    values_from = value
  ) %>%
  rename("Black" = `African-American`,
         "White" = `Caucasian`) %>%
  mutate(Black = round(100 * Black / Total, 2),
         White = round(100 * White / Total, 2)) %>%
  dplyr::select(-Total) %>%
  group_by(Recidivism, Risk) %>%
  summarize(Black = max(Black, na.rm = TRUE),
            White = max(White, na.rm = TRUE)) %>%
  filter((Risk == "High" & Recidivism == "Did Not Reoffend") |
           (Risk == "Low" & Recidivism == "Reoffended")
  ) %>%
  rename("Recidivism Status" = Recidivism,
         "Predicted Risk" = Risk) %>%
  kable(digits = 2,
        caption = "The Percent of Defendants who were Incorrectly Labeled Higher/Lower Risk by Logistic Regression Stratified by Recidivism Status and Race among 9,387 Defandants in Broward County Florida, 2013-2014",
        booktabs = TRUE)
```




## Seldonian Classification {#seldapp}

This section aims to conclude the chapter by illustrating how Seldonian algorithms can mitigate undesirable outcomes made by classifiers in practicality. Consistent with the notation in Chapter \@ref(chap-2), $\Theta$ would be a set of classifiers and $f$ a classifier performance measure, such as logistic loss or the log likelihood. For this application, the Seldonian algorithm will use the logistic loss as its primary objective function. The goal is to use the Seldonian framework to create a model that makes predictions about recidivism that are fair with respect to race, which will be simplified to just two levels: Black and White. Further research can extend this work to include more races.

### Formulating the Seldonian Problem

Without fairness constraints, the standard ML problem is finding a solution $\theta$ that minimizes logistic loss. However, such a solution, as illustrated in Section \@ref(logreg) when fitting a logistic regression model, results in unequal error rates between Black and White defendants when using the COMPAS data set. Defining the discrimination statistic $d(\theta)$ to measure the difference in error rates as in Equation \@ref(ch3eq2), then  $d(\theta_{LR}) = 0.34$ (or $34.18$%). Similarly, for the COMPAS tool, $d(\theta_{COMPAS}) = 0.45$ (or $44.7$%) using this data set. This illustrates that the logistic regression performed slightly better than the COMPAS tool, both in overall accuracy and error rate disparities. However, there is still a significant discrepancy between the error rates for both races.  

\begin{equation}
\label{ch3eq2}
d(\theta) = abs[(FPR | \text{Black} - FPR | \text{White}) + (FNR | \text{White} - FNR | \text{Black})]
\end{equation}

\noindent To minimize $d(\theta)$, $g(\theta)$ will be defined, for some $\epsilon$, as: 

\begin{equation}
\label{ch3eq3}
g(\theta) = abs[(FPR | \text{Black} - FPR | \text{White}) + (FNR | \text{White} - FNR | \text{Black})] - \epsilon.
\end{equation}

\noindent Recall that a Seldonian algorithm ensures that:

\begin{equation}
\label{ch3eq4}
P(g(\theta) \leq 0) \geq 1 - \delta.
\end{equation}

\noindent The problem can now be fully formulated as a Seldonian machine learning problem. That is, using gradient descent, an optimization algorithm for finding a local minimum of a differentiable function, the Seldonian objective is to minimize logistic loss subject to the constraint: 

\begin{equation}
\label{ch3eq3}
P\{abs[(FPR | \text{Black} - FPR | \text{White}) + (FNR | \text{White} - FNR | \text{Black})]  - \epsilon \leq 0 \} \geq 1 - \delta \textit{; } \delta = 0.05.
\end{equation}

$\delta$ will be set to 0.05 to attain 95% confidence that separation (equalized odds) as defined in Chapter \@ref(classfairdef) is satisfied, that is, $d(\theta) \leq \epsilon$. The data will be partitioned into a training set that will be passed into the candidate selection mechanism to compute $\theta_c$. The remaining partition will be used in the safety test to ensure probabilistic satisfaction of the constraint. $\epsilon$ will be set to four values: $0.2, 0.1, 0.05, \text{and } 0.01$. The code to obtain a solution is available as part of the `seldonian-engine` Python library and is displayed in Appendix \@ref(appendix-e), along with the data pre-processing. 

### Evaluating Performance and Fairness

```{r, echo = FALSE}
# read in the data
seldonian_results <- read.csv("/home/dasienga24/Statistics-Senior-Honors-Thesis/Data Sets/COMPAS/compas_seldonian_results_bw.csv")
```


A solution that passed the safety test was obtained for all four values of $\epsilon$, although as $\epsilon$ got smaller, the logistic loss increased, and the overall accuracy decreased. The accuracy was 68.2%, 65.59%, 64.7%, and 64.4% respectively for $\epsilon = 0.2, 0.1, 0.05, 0.01$. Additionally, the models got progressively worse in correctly classifying observations into the positive class, with the final model classifying every observation into the negative class. Each model had higher overall FNR and lower overall FPR than both the COMPAS tool and the logistic regression model. Tables \@ref(tab:ch3table5), \@ref(tab:ch3table6), \@ref(tab:ch3table7), and \@ref(tab:ch3table8) break up the FPR and FNR for Black and White defendants in each of these four cases. When $\epsilon = 0.2, 0.1, 0.05, \text{and } 0.01$, note that $d(\theta) = 0.22, 0.06, 0.007, \text{and } 0$ respectively.

```{r, echo = FALSE}
seldonian_results <- seldonian_results %>%
  mutate(race = ifelse(Black == 1, 'Black', 'White'),
         pred_risk_0.2 = ifelse(risk_0.2 == 0, 'Low', 'High'),
         pred_risk_0.1 = ifelse(risk_0.1 == 0, 'Low', 'High'),
         pred_risk_0.05 = ifelse(risk_0.05 == 0, 'Low', 'High'),
         pred_risk_0.01 = ifelse(risk_0.01 == 0, 'Low', 'High')) 
```


```{r ch3table5, warning = FALSE, message = FALSE, echo = FALSE}
seldonian_results %>%
  dplyr::select(race, pred_risk_0.2, is_recid) %>%
  rename("Risk" = pred_risk_0.2,
         "Race" = race) %>%
  group_by(Race, is_recid) %>%
  mutate(Total = n()) %>%
  group_by(Risk, Race, Total) %>%
  summarise("Reoffended" = count(is_recid == 1),
            "Did Not Reoffend" = count(is_recid == 0)) %>%
  pivot_longer(cols = c("Reoffended", "Did Not Reoffend"),
               names_to = "Recidivism") %>%
  pivot_wider(
    id_cols = c("Risk", "Recidivism", "Total"),
    names_from = "Race",
    values_from = value
  ) %>%
  mutate(Black = round(100 * Black / Total, 2),
         White = round(100 * White / Total, 2)) %>%
  dplyr::select(-Total) %>%
  group_by(Recidivism, Risk) %>%
  summarize(Black = max(Black, na.rm = TRUE),
            White = max(White, na.rm = TRUE)) %>%
  filter((Risk == "High" & Recidivism == "Did Not Reoffend") |
           (Risk == "Low" & Recidivism == "Reoffended")
  ) %>%
  rename("Recidivism Status" = Recidivism,
         "Predicted Risk" = Risk) %>%
  kable(digits = 2,
        booktabs = TRUE,
        caption = "The Percent of Defendants who were Incorrectly Labeled Higher/Lower Risk by a Seldonian Algorithm ($\\epsilon$ = 0.2) Stratified by Recidivism Status and Race among 9,387 Defandants in Broward County Florida, 2013-2014")
```

```{r ch3table6, warning = FALSE, message = FALSE, echo = FALSE}
seldonian_results %>%
  dplyr::select(race, pred_risk_0.1, is_recid) %>%
  rename("Risk" = pred_risk_0.1,
         "Race" = race) %>%
  group_by(Race, is_recid) %>%
  mutate(Total = n()) %>%
  group_by(Risk, Race, Total) %>%
  summarise("Reoffended" = count(is_recid == 1),
            "Did Not Reoffend" = count(is_recid == 0)) %>%
  pivot_longer(cols = c("Reoffended", "Did Not Reoffend"),
               names_to = "Recidivism") %>%
  pivot_wider(
    id_cols = c("Risk", "Recidivism", "Total"),
    names_from = "Race",
    values_from = value
  ) %>%
  mutate(Black = round(100 * Black / Total, 2),
         White = round(100 * White / Total, 2)) %>%
  dplyr::select(-Total) %>%
  group_by(Recidivism, Risk) %>%
  summarize(Black = max(Black, na.rm = TRUE),
            White = max(White, na.rm = TRUE)) %>%
  filter((Risk == "High" & Recidivism == "Did Not Reoffend") |
           (Risk == "Low" & Recidivism == "Reoffended")
  ) %>%
  rename("Recidivism Status" = Recidivism,
         "Predicted Risk" = Risk) %>%
  kable(digits = 2,
        booktabs = TRUE,
        caption = "The Percent of Defendants who were Incorrectly Labeled Higher/Lower Risk by a Seldonian Algorithm ($\\epsilon$ = 0.1) Stratified by Recidivism Status and Race among 9,387 Defandants in Broward County Florida, 2013-2014")
```


```{r ch3table7, warning = FALSE, message = FALSE, echo = FALSE}
seldonian_results %>%
  dplyr::select(race, pred_risk_0.05, is_recid) %>%
  rename("Risk" = pred_risk_0.05,
         "Race" = race) %>%
  group_by(Race, is_recid) %>%
  mutate(Total = n()) %>%
  group_by(Risk, Race, Total) %>%
  summarise("Reoffended" = count(is_recid == 1),
            "Did Not Reoffend" = count(is_recid == 0)) %>%
  pivot_longer(cols = c("Reoffended", "Did Not Reoffend"),
               names_to = "Recidivism") %>%
  pivot_wider(
    id_cols = c("Risk", "Recidivism", "Total"),
    names_from = "Race",
    values_from = value
  ) %>%
  mutate(Black = round(100 * Black / Total, 2),
         White = round(100 * White / Total, 2)) %>%
  dplyr::select(-Total) %>%
  group_by(Recidivism, Risk) %>%
  summarize(Black = max(Black, na.rm = TRUE),
            White = max(White, na.rm = TRUE)) %>%
  filter((Risk == "High" & Recidivism == "Did Not Reoffend") |
           (Risk == "Low" & Recidivism == "Reoffended")
  ) %>%
  rename("Recidivism Status" = Recidivism,
         "Predicted Risk" = Risk) %>%
  kable(digits = 2,
        booktabs = TRUE,
        caption = "The Percent of Defendants who were Incorrectly Labeled Higher/Lower Risk by a Seldonian Algorithm ($\\epsilon$ = 0.05) Stratified by Recidivism Status and Race among 9,387 Defandants in Broward County Florida, 2013-2014")
```

```{r ch3table8, warning = FALSE, message = FALSE, echo = FALSE}
seldonian_results %>%
  dplyr::select(race, pred_risk_0.01, is_recid) %>%
  rename("Risk" = pred_risk_0.01,
         "Race" = race) %>%
  group_by(Race, is_recid) %>%
  mutate(Total = n()) %>%
  group_by(Risk, Race, Total) %>%
  summarise("Reoffended" = count(is_recid == 1),
            "Did Not Reoffend" = count(is_recid == 0)) %>%
  pivot_longer(cols = c("Reoffended", "Did Not Reoffend"),
               names_to = "Recidivism") %>%
  pivot_wider(
    id_cols = c("Risk", "Recidivism", "Total"),
    names_from = "Race",
    values_from = value
  ) %>%
  mutate(Black = round(100 * Black / Total, 2),
         White = round(100 * White / Total, 2)) %>%
  dplyr::select(-Total) %>%
  group_by(Recidivism, Risk) %>%
  summarize(Black = max(Black, na.rm = TRUE),
            White = max(White, na.rm = TRUE)) %>%
  filter((Risk == "High" & Recidivism == "Did Not Reoffend") |
           (Risk == "Low" & Recidivism == "Reoffended")
  ) %>%
  rename("Recidivism Status" = Recidivism,
         "Predicted Risk" = Risk) %>%
  kable(digits = 2,
        booktabs = TRUE,
        caption = "The Percent of Defendants who were Incorrectly Labeled Higher/Lower Risk by a Seldonian Algorithm ($\\epsilon$ = 0.01) Stratified by Recidivism Status and Race among 9,387 Defandants in Broward County Florida, 2013-2014")
```


$\\$

In conclusion, the Seldonian algorithms successfully met the fairness constraints defined, with the FPR and FNR gaining more parity along racial lines for Black and White defendants as $\epsilon$ became more conservative. However, there was a tradeoff with model informativeness and performance in enforcing greater fairness. The FNR got larger as the FPR got smaller until, ultimately, the model was non-informative despite perfectly satisfying the constraints (100% FNR and 0% FPR for both races). Accuracy also dropped as the value of $\epsilon$ decreased, although the original data set could have been more informative. Notably, considering all races, the lowest achievable accuracy would only be 4% lower than the highest accuracy attained by the logistic regression model. 

Looking ahead, there are several avenues for future research. One direction involves extending this study to data sets with less class imbalance and higher overall predictive performance. By doing so, the tradeoffs inherent in incorporating fairness constraints into the traditional objective function in a practical setting can be better elucidated. Chapter \@ref(chap-4) contributes to this understanding by conducting a simulation study to explore the theoretical and practical implications of the Seldonian framework in the classification setting.


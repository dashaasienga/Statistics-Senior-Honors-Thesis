# Seldonian Algorithms for Classification {#chap-3}

```{r, include = FALSE}
library(mosaic)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
library(knitr)
library(kableExtra)
library(ggplot2)
library(GGally)
```

```{r, echo = FALSE}
library(reticulate)
use_python("/cm/shared/apps/amh-Rstudio/python-3.11.4/bin/python3", required = TRUE)
```

```{r, echo = FALSE}
seldonian <- import("seldonian")
```

```{python, echo = FALSE}
import seldonian
```

Chapter \@ref(chap-2) introduced the Seldonian framework, which offers probabilistic guarantees for satisfying defined behavioral constraints. However, the toy linear regression example demonstrated some of the limitations of Seldonian algorithms, particularly in scenarios with limited sample sizes where convergence may pose a challenge. In practice, sample sizes vary. 

Furthermore, many machine learning applications deal with classification problems. Applications range from risk assessment tools like COMPAS, discussed in Chapter \@ref(intro), to credit scoring and employment prediction algorithms, naming a few. However, the deployment of such algorithms raises significant ethical concerns as discussed in Chapters \@ref(intro) and \@ref(chap-2), primarily with regard to fairness and the potential reinforcement of discriminatory practices. Given the historical and social biases inherent in the data used to train these algorithms, there is a pressing need to assess their fairness and mitigate any potential harm they may cause to disadvantaged groups.

To address this concern, this chapter aims to investigate the efficacy and applicability of Seldonian algorithms in practical classification settings. By conducting a simulation study, the aim is to evaluate whether Seldonian approaches can effectively produce fairer outcomes and mitigate discriminatory tendencies, drawing on some of the statistical definitions of fairness from Chapter \@ref(fairnessdefinitions). Specifically, the objective is to assess the feasibility of leveraging Seldonian algorithms to enhance the fairness and equity of predictive models across various classification tasks.

## Simulation Design {#sim-design}

Before conducting the simulation study and analyzing the results, this section provides detailed explanations of the simulation set-up and design. 

### Aims

The aim of this simulation study is to present a proof of concept for the use of the Seldonian framework in classification problems. Seldonian algorithms $\textit{can}$ fail, especially with insufficient data, as elucidated in Chapter \@ref(toy). Solutions returned are also probabilistic. With these limitations in mind, this simulation study aims to compare the predictive performance of Seldonian algorithms with that of the standard ML approach in practical classification settings. 

### Data-Generation Mechanism

Given that this is a proof-of-concept simulation study, the data-generation mechanism will follow a realistic design. In real-world applications, it may be realistic to expect a setting with $p$ different quantitative and categorical variables such that $X = (X_1, X_2, \ldots, X_p)$ is the set of variables. Some, or all, of the $X_i$ variables have moderate to strong correlations with $A$, the protected attribute. The protected attribute, $A$, has varying levels, likely two or three, akin to Black v White or Male v Female. This correlation structure highlights the role that proxies play in group-blind classifiers, even when the protected attribute is not included in the model as a variable. Finally, the $X_i$'s, and $A$ by extension, have moderate to strong correlations with the binary target variable $Y$, further highlighting the varying prevalence of $Y$ for different demographic groups and the inherent bias that may already be present in the training data of classification algorithms. 

Because emulating such a structure can be complex and error-prone and because the aim is to have a realistic data-generation mechanism, rather than generating data from a parametric model, the simulated data sets will be generated by resampling with replacement from the COMPAS data set. 

```{r, echo = FALSE}
#read in the data
compasdata <- read.csv("/home/dasienga24/Statistics-Senior-Honors-Thesis/Data Sets/COMPAS/compas_data1.csv")
```

The COMPAS data set has records of `r length(unique(compasdata$person_id))` people from Broward County, Florida. The data set contains information on each defendant such as their name, sex, age, race, marital status, juvenile felony count, juvenile misdeameanor count, and number of prior offenses. All of the variables are used in the COMPAS tool to calibrate a raw score, which is then used to assess a defendant's risk of recidivism, risk of violence, and  risk of failure to appear in court if granted bail. This is achieved by converting the raw scores into decile scores that then determine whether the defendant's risk is high, medium, or low for the three different types of assessments. Table \@ref(tab:table1) displays how the decile scores are mapped into the three risk levels.

```{r table1, echo = FALSE}
compasdata %>%
  select(decile_score, score_text) %>%
  filter(score_text != 'N/A') %>%
  rename("Risk" = score_text) %>%
  group_by(Risk) %>%
  summarise("Min" = min(decile_score),
            "Max" = max(decile_score)) %>%
  arrange(Min) %>%
  kable(digits = 2,
        caption = "COMPAS Decile Scores",
        booktabs = TRUE)
```

[Discuss Figure \@ref(fig:ch3fig1).]

```{r ch3fig1, warning = FALSE, message = FALSE, echo = FALSE, fig.align='center', fig.cap="Scatterplot Matrix of COMPAS Predictors", warning = FALSE, message = FALSE}
compas_data_gg <- compasdata %>%
  filter(type_of_assessment == 'Risk of Recidivism') %>%
  filter(is_recid != -1) %>%
  filter(score_text != 'N/A') 


ggpairs(data = compas_data_gg,
        columns = c("juv_fel_count", "juv_misd_count", "juv_other_count",   
                    "priors_count"),
        columnLabels = c("Felonies", "Misdemeanors", "Other", "Priors"),
        labeller = "label_parsed")
```

[Discuss Figure \@ref(fig:ch3fig2).]

```{r ch3fig2, warning = FALSE, message = FALSE, echo = FALSE, fig.align='center', fig.cap="Decile Scores by Race", warning = FALSE, message = FALSE}
ggplot(data = compas_data_gg, mapping = aes(x=as.factor(is_recid))) +
  geom_bar() +
  scale_x_discrete(c(0,1)) +
  theme_minimal() +
  facet_wrap( ~ race)
```

[Discuss Figure \@ref(fig:ch3fig3).]

```{r ch3fig3, warning = FALSE, message = FALSE, echo = FALSE, fig.align='center', fig.cap="Prior Offenses by Race", warning = FALSE, message = FALSE}
ggplot(data = compas_data_gg, mapping = aes(x=priors_count)) +
  geom_histogram() +
  theme_minimal() +
  facet_wrap( ~ race)
```


[define notation to be consistent with the COMPAS dat set, may need to do some data massaging here] Consistent with the notation, $X$ is the set of predictors and $Y$ is the risk ...

[Describe the rest of the data-generation mechanism and which populations the results of this simulation study will extend to.]

relationship between A and Y and X and Y?

### Target

The target of this simulation study is prediction, that is, to evaluate Seldonian algorithms for predictive performance of classification outcomes. 

### Methods

[Discuss the methods]

### Performance Measures

Compared to the logistic regression models, the predictive performance of the Seldonian models will be assessed along three dimensions: the accuracy of the solutions, the satisfaction or violation of the behavioral constraint set, and the probability of a Seldonian solution.

For each simulation trial, the overall accuracy of both the Seldonian model and the logistic regression model will be recorded and eventually averaged over the specific sample setting, that is, for a data set with a specific sample size and specific $Y$ prevalence for each demographic group $a \in A$. Both the mean and the standard error will be reported in tabular format and visualized graphically to compare the models' predictive performances and, potentially, evaluate the trade-offs that may occur by employing the Seldonian framework and enforcing a behavioral constraint.

The satisfaction or violation of the behavioral constraint will be assessed in two ways. First, for each sample setting as described above, a count of the times both frameworks satisfied the behavioral constraint will be reported in tabular format. Additionally, the FPR and FNR discrimination statistics, as defined in Equations \@ref(ch3eq1) and \@ref(ch3eq2), respectively, will be recorded for each simulation trial. The mean and standard error will be reported and visualized for each sample setting to compare the magnitude and direction of models' unfairness with regard to the separation fairness definition.

\begin{equation}
\label{ch3eq1}
d_1(\theta) = P (\hat{Y} = 1 | A = a, Y = 0) - P (\hat{Y} = 1 | A = b, Y = 0).
\end{equation}

\begin{equation}
\label{ch3eq2}
d_2(\theta) = P (\hat{Y} = 0 | A = a, Y = 1) - P (\hat{Y} = 0 | A = b, Y = 1).
\end{equation}


Finally, it is essential to account for the fact that the Seldonian algorithms will not always return a solution. Recording the probability of a solution being returned in each sample setting will be crucial for evaluating the practical feasibility of this framework. Additionally, for fair statistical comparisons, the first and second performance measures will be compared only with Seldonian solutions that converge. However, the performance of the logistic regression models in trials where no solutions were found using the Seldonian framework will be analyzed to elucidate learnings about the nature of those trials. 

## Simulation Results {#sim-results}



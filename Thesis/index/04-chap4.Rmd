# Chapter 4 (RENAME & EDIT) {#chap-4}

```{r, include = FALSE}
library(mosaic)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
library(knitr)
library(kableExtra)
library(ggplot2)
library(GGally)
library(MASS)
```

```{r, echo = FALSE}
library(reticulate)
use_python("/cm/shared/apps/amh-Rstudio/python-3.11.4/bin/python3", required = TRUE)
```

```{r, echo = FALSE}
seldonian <- import("seldonian")
```

```{python, echo = FALSE}
import seldonian
```


Chapter \@ref(chap-2) introduced the Seldonian framework, which offers probabilistic guarantees for satisfying defined behavioral constraints. However, the toy linear regression example demonstrated some of the limitations of Seldonian algorithms, particularly in scenarios with limited sample sizes where convergence may pose a challenge. In practice, sample sizes vary. 

Furthermore, many machine learning applications deal with classification problems. Applications range from risk assessment tools like COMPAS, discussed in Chapter \@ref(intro), to credit scoring and employment prediction algorithms, naming a few. However, the deployment of such algorithms raises significant ethical concerns as discussed in Chapters \@ref(intro) and \@ref(chap-2), primarily with regard to fairness and the potential reinforcement of discriminatory practices. Given the historical and social biases inherent in the data used to train these algorithms, there is a pressing need to assess their fairness and mitigate any potential harm they may cause to disadvantaged groups.

To address this concern, this chapter aims to investigate the efficacy and applicability of Seldonian algorithms in practical classification settings. By conducting a simulation study, the aim is to evaluate whether Seldonian approaches can effectively produce fairer outcomes and mitigate discriminatory tendencies, drawing on some of the statistical definitions of fairness from Chapter \@ref(fairnessdefinitions). Specifically, the objective is to assess the feasibility of leveraging Seldonian algorithms to enhance the fairness and equity of predictive models across various classification tasks.

## Simulation Design {#sim-design}

Before conducting the simulation study and analyzing the results, this section provides detailed explanations of the simulation set-up and design. 

### Aims

The aim of this simulation study is to present a proof of concept for the use of the Seldonian framework in classification problems. Seldonian algorithms $\textit{can}$ fail, especially with insufficient data, as elucidated in Chapter \@ref(toy). Solutions returned are also probabilistic. With these limitations in mind, this simulation study aims to compare the predictive performance of Seldonian algorithms with that of the standard ML approach in practical classification settings. 

### Data-Generation Mechanism WIP {#data-gen} 

Given that this is a proof-of-concept simulation study, the data-generation mechanism will follow a realistic design. In real-world applications, it may be realistic to expect a setting with $p$ different quantitative and categorical variables such that $X = (X_1, X_2, \ldots, X_p)$ is the set of variables. Some, or all, of the $X_i$ variables have moderate to strong correlations with $A$, the protected attribute. The protected attribute, $A$, has varying levels, likely two or three, akin to Black v White or Male v Female. This correlation structure highlights the role that proxies play in group-blind classifiers, even when the protected attribute is not included in the model as a variable. Finally, the $X_i$'s, and $A$ by extension, have moderate to strong correlations with the binary target variable $Y$, further highlighting the varying prevalence of $Y$ for different demographic groups and the inherent bias that may already be present in the training data of classification algorithms. 

\noindent *OPTION 1: Generate simulation data in R.*

\noindent I've included the code just so you can look at it. It will not be visible in the final document, perhaps in the appendix instead. I can write up more specifics on it if we decide to go this route. With this approach, we can vary covariate correlations, sample size, and potentially the prevalence of Y for each level of A. 

```{r, warning=FALSE, message=FALSE}
# Set seed for reproducibility
set.seed(123)

# Number of observations
n <- 200

# Number of variables
p <- 3

# Generate covariance matrix for predictor variables 
Sigma <- matrix(c(0.7,0.5, 0.7,0.5), nrow = p, ncol = p)
diag(Sigma) <- 1
Sigma 

# Generate X variables with multivariate normal distribution
X <- mvrnorm(n = n, mu = rep(0, p), Sigma = Sigma)

# Generate protected attribute A with 2 levels
# Assume A is dependent on X 
# Let's say the first variable in X has a strong effect on A
# We will simulate this by adding X[,1] + some noise
A <- X[,1] + rnorm(n)

# Convert Y to binary based on some threshold
A <- as.numeric(A > mean(A))

# Generate binary target variable Y
# Assume Y is dependent on X and A
# Let's say the first variable in X has a strong effect on Y, while A also has an effect
# We will simulate this by adding X[,1] + A + some noise
Y <- X[,1] + A + rnorm(n)

# Convert Y to binary based on some threshold
Y <- as.numeric(Y > mean(Y))

# Check correlation between variables
cor(X, A)
cor(X, Y)
cor(A, Y)

# Create a data frame
data <- data.frame(X, A, Y)

# Print first few rows of the data frame
head(data)
```


\noindent *Option 2: Resample from the COMPAS data set* 

Because emulating such a structure can be complex and error-prone and because the aim is to have a realistic data-generation mechanism, rather than generating data from a parametric model, the simulated data sets will be generated by resampling with replacement from the COMPAS data set. 

```{r, echo = FALSE}
#read in the data
compasdata <- read.csv("/home/dasienga24/Statistics-Senior-Honors-Thesis/Data Sets/COMPAS/compas_data.csv")
```

The COMPAS data set has records of `r length(unique(compasdata$person_id))` people from Broward County, Florida. The data set contains information on each defendant such as their name, sex, age, race, marital status, juvenile felony count, juvenile misdeameanor count, and number of prior offenses. All of the variables are used in the COMPAS tool to calibrate a raw score, which is then used to assess a defendant's risk of recidivism, risk of violence, and  risk of failure to appear if granted bail or parole. This is achieved by converting the raw scores into decile scores that then determine whether the defendant's risk is high, medium, or low for the three different types of assessments. Table \@ref(tab:ch4table1) displays how the decile scores are mapped into the three risk levels.

\noindent [refer to analysis file]

$\\$

\noindent I'll hold off on completing this section until we finalize which data generation mechanism we will us based on the information we now have. To-Do's: 

\noindent - [if resampling from COMPAS, define notation specifically using the COMPAS data set to be consistent with the rest of the thesis] 

\noindent - [overall, need to finalize the rest of this section in a robust way, including what will vary (and what levels they'll have -- refer to Git issue/ adjust below) as well as which populations the results of this simulation study will extend to.]


### Target

The target of this simulation study is prediction, that is, to evaluate Seldonian algorithms for predictive performance of classification outcomes. 

### Methods

As described in Chapter \@ref(chap-2), the Seldonian framework was designed to place probabilistic fairness constraints on traditional algorithms. Solutions produced by Seldonian algorithms will be compared to those produced through the standard ML framework, specifically by logistic regression, to assess the predictive performance and feasibility of the Seldonian framework.

Drawing from the fairness definitions described in Chapter \@ref(fairnessdefinitions) with a particular focus on practical situations, it may be less important that a model satisfies independence. That is, that the model, on average, has the same likelihood of a positive prediction for all demographic groups. Instead, it may be more realistic to expect that the model be equally wrong or equally correct in its predictions of $Y$ for each demographic group. For this reason, two fairness constraints ($n=2$) will be set on the Seldonian algorithms to satisfy separation, otherwise known as equality of the error rates or equality of odds, as defined in Equations \@ref(ch4eq3) and \@ref(ch4eq4). 

1) *Predictive Equality*: equality of false positive rates (FPR)/ Type I error rates across groups:

\begin{equation}
\label{ch4eq3}
g_1(\theta): P (\hat{Y} = 1 | A = a, Y = 0) = P (\hat{Y} = 1 | A = b, Y = 0).
\end{equation}

2) *Equality of Opportunity*: equality of false negative rates (FNR)/ Type II error rates across groups:

\begin{equation}
\label{ch4eq4}
g_2(\theta): P (\hat{Y} = 0 | A = a, Y = 1) = P (\hat{Y} = 0 | A = b, Y = 1).
\end{equation}


Simulated data sets will be generated independently before being fed into both algorithms. The relevant performance measures, as detailed in Section \@ref(performancemeasures), will be recorded for each trial. One thousand trials will be run for each sample setting described in Section \@ref(data-gen), that is, each combination of sample size and $Y$ prevalence. The code will be run in Python using the Rstudio software interface and the Amherst College High-Performance Computing System. The `seldonian` package is readily available for installation in Python -- it is equipped with functions that allow for the implementation of Seldonian algorithms. Other Python packages, such as `pandas`, `numpy`, and `sklearn`, will be helpful in conducting the rest of the simulation study. 


### Performance Measures {#performancemeasures}

Compared to the logistic regression models, the predictive performance of the Seldonian models will be assessed along three dimensions: the accuracy of the solutions, the satisfaction or violation of the behavioral constraints set, and the probability of a Seldonian solution.

For each simulation trial, the overall accuracy of both the Seldonian model and the logistic regression model will be recorded and eventually averaged over the specific sample setting, that is, for a data set with a specific sample size and specific $Y$ prevalence for each demographic group $a \in A$. Both the mean and the standard error will be reported in tabular format and visualized graphically to compare the models' predictive performances and, potentially, evaluate the trade-offs that may occur by employing the Seldonian framework and enforcing behavioral constraints.

The satisfaction or violation of the behavioral constraint will be assessed in two ways. First, for each sample setting as described above, a count of the times both frameworks satisfied the behavioral constraint, by some margin, will be reported in tabular format. Additionally, the FPR and FNR discrimination statistics, as defined in Equations \@ref(ch4eq1) and \@ref(ch4eq2), respectively, will be recorded for each simulation trial. The mean and standard error will be reported and visualized for each sample setting to compare the magnitude and direction of the models' unfairness with regard to the separation fairness definition.

\begin{equation}
\label{ch4eq1}
d_1(\theta) = P (\hat{Y} = 1 | A = a, Y = 0) - P (\hat{Y} = 1 | A = b, Y = 0).
\end{equation}

\begin{equation}
\label{ch4eq2}
d_2(\theta) = P (\hat{Y} = 0 | A = a, Y = 1) - P (\hat{Y} = 0 | A = b, Y = 1).
\end{equation}


Finally, it is essential to account for the fact that the Seldonian algorithms will not always return a solution. Recording the probability of a solution being returned in each sample setting will be crucial for evaluating the practical feasibility of this framework. Additionally, for fair statistical comparisons, the first and second performance measures will be compared only with Seldonian solutions that converge. However, the performance of the logistic regression models in trials where no solutions were found using the Seldonian framework will be analyzed to elucidate learnings about the nature of those trials. 

## Simulation Results {#sim-results}




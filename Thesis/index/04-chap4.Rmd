# Seldonian Algorithms for Classification: A Simulation Study {#chap-4}

```{r, include = FALSE}
library(mosaic)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
library(knitr)
library(kableExtra)
library(ggplot2)
library(GGally)
library(MASS)
```

Chapter \@ref(chap-2) introduced the Seldonian framework, which offers probabilistic guarantees for satisfying defined behavioral constraints. However, the toy linear regression example demonstrated some of the limitations of Seldonian algorithms, particularly in scenarios with limited sample sizes where convergence may pose a challenge. In practice, sample sizes vary. Furthermore, Chapter \@ref(chap-3) applied the Seldonian framework to a classification setting using the COMPAS data set. The goal was to produce recidivism predictions that elicit fairer outcomes along racial lines, with a specific focus on Black and White defendants. However, the application illustrated that while the behavioral constraint was satisfied in all four cases, there was a tradeoff in the model's accuracy. In other words, a non-informative model can be perfectly Seldonian, but what value does a theoretically fair non-informative model add?

To address this concern and further study these tradeoffs, this chapter investigates the efficacy and applicability of Seldonian algorithms in practical classification settings with class balance and better predictive performance than COMPAS. By conducting a simulation study, the aim is to evaluate whether Seldonian approaches can effectively produce fairer outcomes and mitigate discriminatory tendencies, drawing on the fairness notion of separation (or equality of odds) defined in Chapter \@ref(fairnessdefinitions) and set up in Chapter \@ref(seldapp). Specifically, the objective is to assess the feasibility of leveraging Seldonian algorithms to enhance the fairness and equity of predictive models across various practical classification tasks.

## Simulation Design {#sim-design}

Before conducting the simulation study and analyzing the results, this section provides detailed explanations of the simulation set-up and design. 

### Aims

This simulation study presents a proof of concept for using the Seldonian framework in classification problems with robust predictive performance. Seldonian algorithms $\textit{can}$ fail, especially with insufficient data, as elucidated in Chapter \@ref(toy). On the flip side, as elucidated in Chapter \@ref(seldapp), Seldonian algorithms can succeed in their objective for fairer outcomes but fail to produce a useful model. Solutions returned are also probabilistic and may not always satisfy the constraint despite passing the safety test. With these limitations in mind, this simulation study aims to theoretically assess the predictive performance of Seldonian algorithms, compared to that of the standard ML approach, in practical classification settings. 

### Data-Generation Mechanism {#data-gen} 

```{r, echo = FALSE}
compas_sim_path <- "/home/dasienga24/Statistics-Senior-Honors-Thesis/Data Sets/COMPAS/compas_sim.csv"
compas_sim_parent <- read.csv(compas_sim_path)

lr <- glm(is_recid ~ age + prior_offense,
            data = compas_sim_parent,
            family = binomial(logit))

lr_accuracy <- 100*count(round(lr[["fitted.values"]]) == lr[["y"]])/nrow(compas_sim_parent)
```

Given that this is a proof-of-concept simulation study, the data-generation mechanism will follow a realistic design. Two of the most informative variables from the COMPAS data set were selected for a simpler set-up: the defendant's age (continuous) and whether or not the defendant had committed any prior offenses (binary). The choice to use the COMPAS data set as a starting point was so that the complex relationships between the predictor variables ($X$) and the protected attribute ($A$) may be retained, especially given that the data was collected for a practical application and elucidates relationships that may be expected in the real world. There are only two levels of the protected attribute, race, that were retained for the study: Black and White. 

To achieve better predictive performance, a linear combination of age and prior offenses was chosen after searching through a range of plausible values: $5  - 0.2 \textit{Age} + 0.5 \textit{PriorOffense}$. Note that the coefficients should be interpreted in their logarithmic form as the log of odds. The linear combination resulted in a vector of values for each observation in the data set ($n = 9387$), which were then passed into an inverse logistic function to generate probability values. The resulting probability values were then used to randomly draw the binary response variable -- whether or not a defendant recommitted a crime within two years -- from a binomial distribution. Finally, class balance was induced on the data set by randomly sampling, with replacement, 1250 observations from each of the four intersections of race and recidivism status: Black and White defendants who recidivated and did not recidivate. Note that this scheme (Appendix \@ref(appendix-f)) assumes equal prevalence of the response variable, $Y$, for both levels of the protected attribute. 

The parent simulation data set, thus, contains 5000 observations, achieves perfect class balance, and has a baseline logistic regression accuracy of `r lr_accuracy`%. This offers a realistic improvement from the accuracy of 70.2% obtained from the COMPAS logistic regression. However, because of the class balance, the lowest achievable accuracy is now 50% (a random/ coin-flip model) rather than 64.4%. This will allow more room for the Seldonian algorithm model accuracies to vary. 

Two hundred total data sets of size $n = 500$, $n = 1000$, $n = 2500$, and $n = 5000$ will be sampled, with replacement, from this parent data set for the simulation study, with 50 data sets in each of the four partitions. 

### Target

The target of this simulation study is prediction, that is, to evaluate Seldonian algorithms for predictive performance in classification settings. 

### Methods

Because the Seldonian framework was designed to place probabilistic fairness constraints on traditional algorithms, solutions produced by Seldonian algorithms will be compared to those produced through the standard ML framework, specifically logistic regression, to assess the predictive performance and feasibility of the Seldonian framework.

Simulated data sets will be generated independently before being fed into both algorithms. The relevant performance measures, as detailed in Section \@ref(performancemeasures), will be recorded for each trial. Fifty trials will be run for each sample size as described in Section \@ref(data-gen). The code will be run in Python using the Rstudio software interface and the Amherst College High-Performance Computing System. The `seldonian` package is readily available for installation in Python and is equipped with functions that allow for the implementation of Seldonian algorithms. Other Python packages, such as `pandas`, `numpy`, and `sklearn`, will help conduct the rest of the simulation study. 


### Performance Measures {#performancemeasures}

Compared to the logistic regression models, the predictive performance of the Seldonian models will be assessed along three dimensions: the accuracy of the solutions, the satisfaction or violation of the behavioral constraints set, and the probability of a Seldonian solution across all trials within a specific setting (sample size).

For each simulation trial, the overall accuracy of both the Seldonian model and the logistic regression model will be recorded and eventually averaged over the specific sample size. Both the mean and the standard error will be reported in tabular format and visualized graphically to compare the models' predictive performances and, potentially, evaluate the trade-offs that may occur by employing the Seldonian framework and enforcing behavioral constraints.

Drawing from the fairness definitions described in Chapter \@ref(fairnessdefinitions) with a particular focus on the COMPAS example in Chapter \@ref(chap-3), it may be less important that a model satisfies independence. That is, that the model, on average, has the same likelihood of a positive prediction for all levels of the protected attribute. Instead, it may be more realistic to expect that the model be equally wrong or equally correct in its predictions of $Y$ for each protected attribute. For this reason, one fairness constraint will be set on the Seldonian algorithms to satisfy separation, otherwise known as equality of the error rates or equality of odds, as defined in Equation \@ref(ch4eq1) within some margin $\epsilon$ and with $1 - \delta$ % confidence. Similar to Chapter \@ref(seldapp), $\epsilon$ will be set to four levels: $0.2, 0.1, 0.05, \text{and } 0.01$. $\delta$ will be set to $0.05$ to guarantee 95% confidence. 

\begin{equation}
\label{ch4eq1}
g(\theta): abs[(FPR | \text{A = a} - FPR | \text{A = b}) + (FNR | \text{A = a} - FNR | \text{A = b})] - \epsilon.
\end{equation}

The satisfaction or violation of the behavioral constraint will be assessed in two ways. First, for each sample size as described above, a count of the times both frameworks satisfied the behavioral constraint, by some margin $\epsilon$, will be reported in tabular format. Additionally, the discrimination statistics as defined in Equation \@ref(ch4eq2) will be recorded for each simulation trial. The mean and standard error will be reported and visualized for each sample setting to compare the magnitude and direction of the models' unfairness with regard to the separation fairness definition.

\begin{equation}
\label{ch4eq2}
d(\theta) = abs[(FPR | \text{A = a} - FPR | \text{A = b}) + (FNR | \text{A = a} - FNR | \text{A = b})]
\end{equation}

Finally, it is essential to account for the fact that the Seldonian algorithms will not always return a solution. Recording the probability of a solution being returned in each sample setting will be crucial for evaluating the practical feasibility of this framework. Additionally, for fair statistical comparisons, the first and second performance measures will be compared only with Seldonian solutions that converge. However, the performance of the logistic regression models in trials where no solutions were found using the Seldonian framework will be analyzed to elucidate learnings about the nature of those trials. 

## Simulation Results {#sim-results}



